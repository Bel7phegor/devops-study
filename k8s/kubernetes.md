<h1>M·ª•c l·ª•c</h1>

- [1. Kh·ªüi ƒë·∫ßu](#1-kh·ªüi-ƒë·∫ßu)
  - [1.1. Kubernetes l√† g√¨? (K8S) {c}](#11-kubernetes-l√†-g√¨-k8s-c)
  - [1.2. M√¥ h√¨nh tri·ªÉn khai](#12-m√¥-h√¨nh-tri·ªÉn-khai)
  - [1.3. Khi n√†o n√™n s·ª≠ d·ª•ng k8s](#13-khi-n√†o-n√™n-s·ª≠-d·ª•ng-k8s)
  - [1.4. H·∫° t·∫ßng k8s](#14-h·∫°-t·∫ßng-k8s)
    - [1.4.1. Ki·∫øn tr√∫c k8s](#141-ki·∫øn-tr√∫c-k8s)
    - [1.4.2. L·∫•y v√≠ d·ª• v·ªÅ m√¥ h√¨nh](#142-l·∫•y-v√≠-d·ª•-v·ªÅ-m√¥-h√¨nh)
- [2. C√†i ƒë·∫∑t c·ª•m k8s](#2-c√†i-ƒë·∫∑t-c·ª•m-k8s)
  - [2.1. Ph∆∞∆°ng ph√°p c√†i ƒë·∫∑t](#21-ph∆∞∆°ng-ph√°p-c√†i-ƒë·∫∑t)
    - [2.1.1. C√†i ƒë·∫∑t tr√™n On-premise](#211-c√†i-ƒë·∫∑t-tr√™n-on-premise)
    - [2.1.2. Cloud](#212-cloud)
- [3. Tri·ªÉn khai d·ª± √°n th·ª±c t·∫ø](#3-tri·ªÉn-khai-d·ª±-√°n-th·ª±c-t·∫ø)
  - [3.1. Quy tr√¨nh ki·∫øn khai d·ª± √°n k8s](#31-quy-tr√¨nh-ki·∫øn-khai-d·ª±-√°n-k8s)
    - [3.1.1. Yaml trong k8s](#311-yaml-trong-k8s)
    - [3.1.2. Namespace k8s](#312-namespace-k8s)
  - [3.2. T∆∞ duy tri·ªÉn khai d·ª± √° tr√™n Kubernetes](#32-t∆∞-duy-tri·ªÉn-khai-d·ª±-√°-tr√™n-kubernetes)
  - [3.3. C√°c c√¥ng c·ª• qu·∫£n l√Ω k8s](#33-c√°c-c√¥ng-c·ª•-qu·∫£n-l√Ω-k8s)
  - [3.4. C√†i ƒë·∫∑t Rancher v√† k·∫øt n·ªëi Kubernetes](#34-c√†i-ƒë·∫∑t-rancher-v√†-k·∫øt-n·ªëi-kubernetes)
    - [3.4.1. Rancher l√†m ƒë∆∞·ª£c g√¨?](#341-rancher-l√†m-ƒë∆∞·ª£c-g√¨)
    - [3.4.2. C√°c c√°ch c√†i ƒë·∫∑t](#342-c√°c-c√°ch-c√†i-ƒë·∫∑t)
      - [3.4.2.1. Ch·∫°y b·∫±ng docker](#3421-ch·∫°y-b·∫±ng-docker)
      - [3.4.2.2. C√†i ƒë·∫∑t tr√™n Rancher tr√™n Cloud (GCP)](#3422-c√†i-ƒë·∫∑t-tr√™n-rancher-tr√™n-cloud-gcp)
  - [3.5. Pod K8s](#35-pod-k8s)
    - [3.5.1. Tri·ªÉn khai v√≠ d·ª• m·ªôt pod](#351-tri·ªÉn-khai-v√≠-d·ª•-m·ªôt-pod)
      - [3.5.1.1. C·∫•u h√¨nh ch·ªãu t·∫£i cho pod](#3511-c·∫•u-h√¨nh-ch·ªãu-t·∫£i-cho-pod)
  - [3.6. Deployment k8s](#36-deployment-k8s)
    - [3.6.1. V√≠ d·ª• m·ªôt file yaml Deployment ƒë∆°n gi·∫£n](#361-v√≠-d·ª•-m·ªôt-file-yaml-deployment-ƒë∆°n-gi·∫£n)
  - [3.7. C√°c c√¢u l·ªánh Deployment K8s](#37-c√°c-c√¢u-l·ªánh-deployment-k8s)
  - [3.8. C√°c chi·∫øn l∆∞·ª£c deployment k8s](#38-c√°c-chi·∫øn-l∆∞·ª£c-deployment-k8s)
    - [3.8.1. Rolling Update](#381-rolling-update)
    - [3.8.2. Recreate](#382-recreate)
  - [3.9. Services](#39-services)
    - [3.9.1. NodePort](#391-nodeport)
      - [3.9.1.1. On-premit](#3911-on-premit)
      - [3.9.1.2. On Cloud](#3912-on-cloud)
    - [3.9.2. ClusterIP](#392-clusterip)
  - [3.10. Helm](#310-helm)
    - [3.10.1. M·ª•c ƒë√≠ch c·ªßa Helm](#3101-m·ª•c-ƒë√≠ch-c·ªßa-helm)
    - [3.10.2. C·∫•u tr√∫c c·ªßa Helm Chart](#3102-c·∫•u-tr√∫c-c·ªßa-helm-chart)
    - [3.10.3. M·ªôt s·ªë l·ªánh Helm c∆° b·∫£n](#3103-m·ªôt-s·ªë-l·ªánh-helm-c∆°-b·∫£n)
    - [3.10.4. Helm Repo l√† g√¨?](#3104-helm-repo-l√†-g√¨)
    - [3.10.5. L·ª£i √≠ch c·ªßa Helm](#3105-l·ª£i-√≠ch-c·ªßa-helm)
  - [3.11. Ingress](#311-ingress)
    - [3.11.1. On-Premit](#3111-on-premit)
      - [3.11.1.1. Th√†nh ph·∫ßn ch√≠nh c·ªßa Ingress:](#31111-th√†nh-ph·∫ßn-ch√≠nh-c·ªßa-ingress)
      - [3.11.1.2. C√†i ƒë·∫∑t v√† c·∫•u h√¨nh Nginx Ingress Controller](#31112-c√†i-ƒë·∫∑t-v√†-c·∫•u-h√¨nh-nginx-ingress-controller)
      - [3.11.1.3. Tri·ªÉn khai loadbalancer](#31113-tri·ªÉn-khai-loadbalancer)
    - [3.11.2. On Cloud](#3112-on-cloud)
  - [3.12. Template yaml](#312-template-yaml)
  - [3.13. Tri·ªÉn khai d·ª± √°n Fullstack](#313-tri·ªÉn-khai-d·ª±-√°n-fullstack)
    - [3.13.1. M√¥ h√¨nh d·ª± √°n](#3131-m√¥-h√¨nh-d·ª±-√°n)
      - [3.13.1.1. Frontend](#31311-frontend)
      - [3.13.1.2. Backend](#31312-backend)
  - [3.14. Configmaps](#314-configmaps)
    - [3.14.1. M·ª•c ƒë√≠ch s·ª≠ d·ª•ng ConfigMap](#3141-m·ª•c-ƒë√≠ch-s·ª≠-d·ª•ng-configmap)
    - [3.14.2. C√°ch t·∫°o v√† s·ª≠ d·ª•ng ConfigMap](#3142-c√°ch-t·∫°o-v√†-s·ª≠-d·ª•ng-configmap)
    - [3.14.3. L∆∞u √Ω](#3143-l∆∞u-√Ω)
  - [3.15. Secret](#315-secret)
    - [3.15.1. C√°c lo·∫°i secret ph·ªï bi·∫øn](#3151-c√°c-lo·∫°i-secret-ph·ªï-bi·∫øn)
    - [3.15.2. C√°ch s·ª≠ d·ª•ng](#3152-c√°ch-s·ª≠-d·ª•ng)
  - [3.16. Request v√† limit](#316-request-v√†-limit)
    - [3.16.1. M·ª•c ƒë√≠ch:](#3161-m·ª•c-ƒë√≠ch)
    - [3.16.2. Kh√°c bi·ªát](#3162-kh√°c-bi·ªát)
    - [3.16.3. C√°c lo·∫°i t√†i nguy√™n ch√≠nh](#3163-c√°c-lo·∫°i-t√†i-nguy√™n-ch√≠nh)
  - [3.17. HPA (autoscale)](#317-hpa-autoscale)
    - [3.17.1. Horiontal Pod Autoscaler (HPA)](#3171-horiontal-pod-autoscaler-hpa)
    - [3.17.2. Metric Server](#3172-metric-server)
  - [3.18. S·ª≠ d·ª•ng Rancher](#318-s·ª≠-d·ª•ng-rancher)
  - [3.19. S·ª≠ d·ª•ng RBAC Rancher](#319-s·ª≠-d·ª•ng-rbac-rancher)
- [4. X√¢y d·ª±ng c√¥ng c·ª• d·ª± √°n](#4-x√¢y-d·ª±ng-c√¥ng-c·ª•-d·ª±-√°n)
  - [4.1. Tri·ªÉn khai c√¥ng c·ª•](#41-tri·ªÉn-khai-c√¥ng-c·ª•)
  - [4.2. StorageClass](#42-storageclass)
    - [4.2.1. ·ª®ng d·ª•ng](#421-·ª©ng-d·ª•ng)
    - [4.2.2. NFS](#422-nfs)
    - [4.2.3. C√∫ ph√°p khai b√°o](#423-c√∫-ph√°p-khai-b√°o)
  - [4.3. PV (Persistent Volume) v√† PVC (Persistent Volume Claim)](#43-pv-persistent-volume-v√†-pvc-persistent-volume-claim)
    - [4.3.1. PV l√† g√¨?](#431-pv-l√†-g√¨)
    - [4.3.2. PVC l√† g√¨?](#432-pvc-l√†-g√¨)
    - [4.3.3. Nh·ªØng ph·∫ßn ƒë·∫∑c bi·ªát ph·∫£i bi·∫øt khi s·ª≠ d·ª•ng PV v√† PVC](#433-nh·ªØng-ph·∫ßn-ƒë·∫∑c-bi·ªát-ph·∫£i-bi·∫øt-khi-s·ª≠-d·ª•ng-pv-v√†-pvc)
    - [4.3.4. C√∫ ph√°p, c√¢u l·ªánh](#434-c√∫-ph√°p-c√¢u-l·ªánh)
      - [4.3.4.1. PVC Example](#4341-pvc-example)
    - [4.3.5. S·ª≠ d·ª•ng v√†o d·ª± √°n](#435-s·ª≠-d·ª•ng-v√†o-d·ª±-√°n)
  - [4.4. Tri·ªÉn khai mariadb](#44-tri·ªÉn-khai-mariadb)
    - [4.4.1. StatefulSet](#441-statefulset)
    - [4.4.2. Tri·ªÉn khai](#442-tri·ªÉn-khai)
  - [4.5. Tri·ªÉn khai Redis (Helm)](#45-tri·ªÉn-khai-redis-helm)
- [5. Gi√°m s√°t v√† qu·∫£n tr·ªã Kubernetes](#5-gi√°m-s√°t-v√†-qu·∫£n-tr·ªã-kubernetes)
  - [5.1. Daemonsets](#51-daemonsets)
  - [5.2. Gi√°m s√°t s·ª≠ d·ª•ng prometheus](#52-gi√°m-s√°t-s·ª≠-d·ª•ng-prometheus)
    - [5.2.1. M√¥ h√¨nh PNG (prometheus node exporter grafana)](#521-m√¥-h√¨nh-png-prometheus-node-exporter-grafana)
    - [5.2.2. C√†i ƒë·∫∑t (helm)](#522-c√†i-ƒë·∫∑t-helm)
  - [5.3. DashBoard Grafana](#53-dashboard-grafana)
  - [5.4. Uptime kuma (helm)](#54-uptime-kuma-helm)
    - [5.4.1. C·∫•u h√¨nh](#541-c·∫•u-h√¨nh)
    - [5.4.2. Truy c·∫≠p v√† t√πy ch·ªânh giao di·ªán](#542-truy-c·∫≠p-v√†-t√πy-ch·ªânh-giao-di·ªán)
  - [5.5. Backup](#55-backup)
    - [5.5.1. Backup nh·ªØng g√¨?](#551-backup-nh·ªØng-g√¨)
    - [5.5.2. Backup and Restore](#552-backup-and-restore)
      - [5.5.2.1. Velero](#5521-velero)
      - [5.5.2.2. C√†i ƒë·∫∑t](#5522-c√†i-ƒë·∫∑t)
      - [5.5.2.3. Ti·∫øn h√†nh backup t·ª´ng ph·∫ßn](#5523-ti·∫øn-h√†nh-backup-t·ª´ng-ph·∫ßn)

# 1. Kh·ªüi ƒë·∫ßu
## 1.1. Kubernetes l√† g√¨? (K8S) {c}

```
L√† n·ªÅn t·∫£ng m√£ ngu·ªìn m·ªü ƒë·ªÉ t·ª± ƒë·ªông tri·ªÉn khai, scaling, m·ªü r·ªông v√† qu·∫£n l√Ω c√°c ·ª©ng d·ª•ng ƒë√≥ng g√≥i trong container, ho·∫°t ƒë·ªông nh∆∞ m·ªôt h·ªá ƒëi·ªÅu h√†nh cho c√°c container (th∆∞·ªùng l√† Docker)
```

## 1.2. M√¥ h√¨nh tri·ªÉn khai
- M√¥ h√¨nh tri·ªÉn khai
    ![alt text](Images/image-6.png)
## 1.3. Khi n√†o n√™n s·ª≠ d·ª•ng k8s 
- C·∫ßn ph·∫£i ƒë·∫£m b·∫£o 4 y·∫øu t·ªë ƒë·ªÉ √°p d·ª•ng gi·∫£i ph√°p n√†o ƒë√≥: Hi·ªáu qu·∫£, v·∫≠n h√†nh, minh b·∫°ch, kh·∫£ nƒÉng v·∫≠n h√†nh, t·ªëi ∆∞u chi ph√≠

    ![alt text](Images/image-10.png)
## 1.4. H·∫° t·∫ßng k8s
### 1.4.1. Ki·∫øn tr√∫c k8s 

![alt text](Images/image-11.png)

### 1.4.2. L·∫•y v√≠ d·ª• v·ªÅ m√¥ h√¨nh
- Trong 1 c√¥ng ty th√¨ c√≥: 
    - Ban qu·∫£n l√Ω c√≥ ch·ª©a:  
        - 1 √¥ng gi√°m ƒë·ªëc th∆∞·ªùng s·∫Ω 0 lam vc tr·ª±c ti·∫øp v·ªõi mn m√† s·∫Ω th√¥ng qua 1 th∆∞ k√Ω
        mn s·∫Ω nh·∫≠n yc c≈©ng nh∆∞ ƒë∆∞a yc ƒë·∫øn tr·ª£ l√Ω n√†y.
        - VD: Ai mu·ªën g·∫∑p GD s·∫Ω ph·∫£i g·∫∑p th∆∞ k√Ω d·ªÉ s·∫Øp x·∫øp l·ªãch hay nh·ªØng yc v·ªÅ nv ban xu·ªëng 
        - CTy s·∫Ω c√≥ vp ƒë·ªÉ l∆∞u tr·ªØ nh·ªØng t√†i li·ªáu v·ªÅ thu·∫ø, nh√¢n s·ª±, ph√≤ng ban,...(Kho t√†i li·ªáu)
        - C√≥ 1 √¥ng GD nh√¢n s·ª±: ch·ªãu tr√°ch nhi·ªám ph√¢n b·ªï nh√¢n vi√™n v√†o c√°c ph√≤ng ban ph√π h·ª£p d·ª±a tr√™n kh·∫£ nƒÉng v√† yc c·ªßa t·ª´ng d·ª± √°n, √¥ n√†y s·∫Ω xem ph√≤ng ban n√†o s·∫Ω c·∫ßn nv sau ƒë√≥ s·∫Ω ƒë∆∞a nv v√†o ƒë√∫ng v·ªã tr√≠.
        - ƒê·ªÉ ƒë·∫£m b·∫£o c√¥ng vi·ªác ƒë∆∞·ª£c tr∆°n tru th√¨ s·∫Ω c√≥ m·ªôt c√° nh√¢n ho·∫∑c 1 ph√≤ng ban gi√°m s√°t ch·∫•t l∆∞·ª£ng l√† ng∆∞·ªùi theo d√µi cv h·∫±ng ng√†y ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng m·ªçi th·ª© ƒë·ªÅu ƒë∆∞·ª£c hd tr∆°n tru. 
        VD: n·∫øu c√≥ v·∫•n ƒë·ªÅ v·ªÅ nh√¢n vi√™n ngh·ªâ vc th√¨ b·ªô ph·∫≠n gi√°m s√°t n√†y s·∫Ω ngay l·∫≠p t·ª©c thay th·∫ø ho·∫∑c b√†n giao cv m·ªõi cho nh√¢n s·ª± m·ªõi ƒë·ªÉ ƒë·∫£m b·∫£o c√¥ng vi·ªác s·∫Ω kh√¥ng b·ªã ƒë√¨nh tr·ªá
    - C√≥ c√°c ph√≤ng ban l√†m vi·ªác chung: {c}
        - T·ª´ng ph√≤ng ban s·∫Ω c√≥ tr∆∞·ªüng ph√≤ng: c√≥ tr√°ch nhi·ªám qu·∫£n l√Ω v√† theo d√µi c√¥ng vi·ªác c·ªßa ph√≤ng ban m√¨nh, khi ban qu·∫£n l√Ω giao nv th√¨ tr∆∞·ªüng ph√≤ng s·∫Ω ƒë·∫£m b·∫£o r·∫±ng m·ªçi ng∆∞·ªùi ƒë·ªÅu hi·ªÉu v√† th·ª±c hi·ªán ƒë√∫ng c√¥ng vi·ªác nv c·ªßa m√¨nh 
        - Nh√¢n s·ª± l√†m vc chuy√™n m√¥n, m·ªói b·∫°n s·∫Ω c√≥ 1 ho·∫∑c nhi·ªÅu kƒ© nƒÉng chuy√™n m√¥n. VD: code fullstack, AI,...
        - Nh√¢n vi√™n k·∫øt n·ªëi: C√°c ph√≤ng ban giao ti·∫øp ƒë∆∞·ª£c v·ªõi nhau v√† giao ti·∫øp ƒëi ra b√™n ngo√†i s·∫Ω c√≥ 1 nh√¢n s·ª± h·ªó tr·ª£ ·ªü c√°c ph√≤ng gi√∫p vc h·ª£p t√°c gi·ªØa c√°c nh√¢n s·ª± ƒë∆∞·ª£c tr∆°n tru h∆°n


- Control Plane: (ban qu·∫£n l√Ω):
    - Cloud-control-manager: N·∫øu c·ª•m k8s c·∫ßn cloud th√¨ s·∫Ω c√≥.
    - kube-api-server: L√† 1 api ƒë·ªÉ c√≥ 1 quy chu·∫©n chung ƒë·ªÉ giao ti·∫øp ·ªü ngo√†i v√†o trong c·ª•m. 
    - etcd: c∆° s·ªü d·ªØ li·ªáu ph√¢n t√°n, l∆∞u tr·ªØ m·ªçi c·∫•u h√¨nh c·ªßa k8s c√°c tr·∫°ng th√°i c·ªßa pod, node c√°c t√†i nguy√™n √Ω nh∆∞ m·ªôt kho l∆∞u tr·ªØ.
    - scheduler: Tr√°ch nhi·ªám ph√¢n ph·ªëi pod ƒë·∫øn c√°c node ·ªü trong cluster v√† xem x√©t c√°c y·∫øu t·ªë nh∆∞ t√†i nguy√™n, cpu, ram, c√°c ch√≠nh s√°ch, c√°c yc c·ª• th·ªÉ kh√°c. (VD: Ch·ªâ ƒë·ªãnh pod v√†o c√°i node n√†o ), ch·∫°y m·ªôt th·ª±c to√°n l·∫≠p l·ªánh ƒë·ªÉ t·ªëi ∆∞u h√≥a ph√¢n b·ªï work lot: x√°c ƒë·ªãnh xem node n√†o c√≥ t√†i nguy√™n ph√π h·ª£p nh·∫•t ƒë·ªÉ tri·ªÉn khai c√°c pod l√™n.
    - Controller Manager: qu·∫£n √Ω c√°c controller l√† nh·ªØng ti·∫øn tr√¨nh ch·ªãu tr√°ch nhi·ªám gi√°m s√°t tr·∫°ng th√°i c·ªßa cluster v√† th·ª±c hi·ªán c√°c h√†nh ƒë·ªông s·ª≠a ch·ªØa t·ª± ƒë·ªông n·∫øu c·∫ßn (pod c√≥ v·∫•n ƒë·ªÅ th√¨ CM s·∫Ω qu·∫£n l√Ω).
- Node: C√≥ nhi·ªÅu node t∆∞∆°ng ·ª©ng v·ªõi ph√≤ng ban l√†m vi·ªác trong ƒë√≥
    - pod: nh√¢n s·ª± chuy√™n m√¥n, m·ªôt node s·∫Ω c√≥ nhi·ªÅu pod v√† 1 pod s·∫Ω c√≥ nhi·ªÅu container (ƒë∆°n v·ªã nh·ªè nh·∫•t)
    - kubelet(tr∆∞·ªüng ph√≤ng): Nh·∫≠n y√™u c·∫ßu t·ª´ kube-api-server ƒë·ªÉ th·ª±c thi c√°c pod tr√™n nod (hay vi·ªác tr∆∞·ªüng ph√≤ng s·∫Ω giao v√† gi√°m s√°t c√°c c√¥ng vi·ªác c·ªßa c√°c nh√¢n s·ª± ·ªü trg ph√≤ng v)
    - kube-proxy (Nh√¢n vi√™n k·∫øt n·ªëi): Th√†nh ph·∫ßn network ch·∫°y tr√™n m·ªói node ƒë·ªÉ cho ph√©p c√°c pod giao ti·∫øp v·ªõi nhau v√† giao ti·∫øp ra b√™n ngo√†i(hay k·∫øt n·ªëi c√°c nh√¢n s·ª± v·ªõi nhau)
# 2. C√†i ƒë·∫∑t c·ª•m k8s
## 2.1. Ph∆∞∆°ng ph√°p c√†i ƒë·∫∑t
- C√°c c√°ch th√¥ng d·ª•ng nh·∫•t: ch·ªçn c√°i ph√π h·ª£p nh·∫•t
Search:"How many way are there to install kubernetes"
- C√≥ 2 c√°ch ch√≠nh: th·ªß c√¥ng(Kubeadm) v√† t·ª± ƒë·ªông (kyops)
### 2.1.1. C√†i ƒë·∫∑t tr√™n On-premise
- M√¥ h√¨nh K8s cluster
    ![M√¥ h√¨nh cluster](Images/image.png)
    - Server n√†o ƒë√≥ng vai tr√≤ l√† control plane th√¨ m·∫∑c ƒë·ªãnh n√≥ kh√¥ng th·ªÉ tri·ªÉn khai d·ª± √°n l√™n ƒë√≥
    - Vi·ªác ƒëi·ªÅu h√†nh c√≥ th·ªÉ b·ªã ·∫£nh h∆∞·ªüng, g√¢y ra cao t·∫£i v√† ·∫£nh h∆∞·ªõng ƒë·∫øn server 
    - M·ªôt m√¥ h√¨nh v·ªõi 3 control plane v√† worker 
        - C√≥ th·ªÉ tri·ªÉn khai d·ª± √°n tr√™n c·∫£ 3 server 
        - Kh√° ph·ªï bi·∫øn 
        
        ![alt text](Images/image-1.png)
- T·∫°o c√°c servers k8s
    - T·∫°o 3 server ubuntu 

    | Hostname	    |     OS	    |         IP	| RAM (t·ªëi thi·ªÉu) | CPU (t·ªëi thi·ªÉu) |
    |:-------------:|---------------|:-------------:|:---------------:|:---------------:|
    | k8s-master-1	| Ubuntu 22.04	| 192.168.1.111	|        3G	      |      2          |
    | k8s-master-2	| Ubuntu 22.04	| 192.168.1.112	|        3G	      |      2          |
    | k8s-master-3	| Ubuntu 22.04	| 192.168.1.113	|        3G	      |      2          |

    - Th·ª±c hi·ªán tr√™n c·∫£ 3 servers
        - Th√™m hosts:(vi /etc/hosts): 
            - N·ªôi dung c·∫•u h√¨nh:

            ```
            192.168.1.111 k8s-master-1
            192.168.1.112 k8s-master-2
            192.168.1.113 k8s-master-3
            ```

        - C·∫≠p nh·∫≠t v√† n√¢ng c·∫•p h·ªá th·ªëng
            ```
            sudo apt update -y && sudo apt upgrade -y
            ```
        - T·∫°o user devops v√† chuy·ªÉn sang user devops
            ```
            adduser devops
            usermod -aG sudo devops
            su devops
            cd /home/devops
            ```
        - T·∫Øt swapoff: 
          -  T·∫°m th·ªùi: `sudo swapoff -a`
          - Vƒ©nh vi·ªÖn
            ```
            vi /etc/fstab 
            #/swap.img
            ho·∫∑c 
            sudo sed -i '/swap.img/s/^/#/' /etc/fstab
            ```
        - C·∫•u h√¨nh module kernel: `vi /etc/modules-load.d/containerd.conf`
            ```
            sudo tee /etc/modules-load.d/containerd.conf <<EOF
            overlay
            br_netfilter
            EOF
            ```
        - T·∫£i module kernel
            ```
            sudo modprobe overlay
            sudo modprobe br_netfilter
            ```
        - C·∫•u h√¨nh h·ªá th·ªëng m·∫°ng:
            ```
            sudo tee /etc/sysctl.d/kubernetes.conf <<EOF
            net.bridge.bridge-nf-call-ip6tables = 1
            net.bridge.bridge-nf-call-iptables = 1
            net.ipv4.ip_forward = 1
            EOF
            ```
            √Åp d·ª•ng c·∫•u h√¨nh sysctl
            > sudo sysctl --system
        - C√†i ƒë·∫∑t c√°c g√≥i c·∫ßn thi·∫øt v√† th√™m kho Docker
            ```
            sudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates
            sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/docker.gpg
            sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
            ```
        - C√†i ƒë·∫∑t containerd 
            ```
            sudo apt update -y
            sudo apt install -y containerd.io
            ```
        - C·∫•u h√¨nh containerd        
            ```
            containerd config default | sudo tee /etc/containerd/config.toml >/dev/null 2>&1
            sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
            ```
            - Kh·ªüi ƒë·ªông containerd
                ```
                sudo systemctl restart containerd
                sudo systemctl enable containerd
                ```
        - Th√™m kho l∆∞u tr·ªØ Kubernetes
            ```
            echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list
            curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
            ```
        - C√†i ƒë·∫∑t c√°c g√≥i Kubernetes
            ```
            sudo apt update -y
            sudo apt install -y kubelet kubeadm kubectl
            sudo apt-mark hold kubelet kubeadm kubectl
            ```
- C√†i ƒë·∫∑t k8s cluster 1 master 2 worker
    - Th·ª±c hi·ªán tr√™n server k8s-master-1
        ```
        sudo kubeadm init
        mkdir -p $HOME/.kube
        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
        sudo chown $(id -u):$(id -g) $HOME/.kube/config
        (ki·∫øm tra tr·∫°ng th√°i c√°c node)
        kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml
        kubectl get nodes 
        ```
    - Th·ª±c hi·ªán tr√™n server k8s-master-2 v√† k8s master-3
        ```
        sudo kubeadm join 192.168.1.111:6443 --token your_token --discovery-token-ca-cert-hash your_sha
        ```
- Kh·ªëi l·ªánh reset c·ª•m khi ƒë√£ kh·ªüi t·∫°o c·ª•m (√°p d·ª•ng tr√™n c·∫£ 3 server)
    ```
    sudo kubeadm reset -f
    sudo rm -rf /var/lib/etcd
    sudo rm -rf /etc/kubernetes/manifests/*
    ```
- C√†i ƒë·∫∑t k8s cluster 3 master worker
    - Th·ª±c hi·ªán tr√™n server k8s-master-1
        ```
        sudo kubeadm init --control-plane-endpoint "192.168.1.111:6443" --upload-certs
        mkdir -p $HOME/.kube 
            --control-plane-endpoint "192.168.1.111:6443": Ch·ªâ ƒë·ªãnh ai l√† master khi join v√†o
            --upload-certs: X√°c th·ª±c cho c√°c server kh√°c mu·ªën join v√†o
        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 
        sudo chown $(id -u):$(id -g) $HOME/.kube/config
        kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml
    - Th·ª±c hi·ªán tr√™n server k8s-master-2 v√† k8s-master-3 
        ```
        sudo kubeadm join 192.168.1.111:6443 --token your_token --discovery-token-ca-cert-hash your_sha --control-plane --certificate-key your_cert
        mkdir -p $HOME/.kube 
        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 
        sudo chown $(id -u):$(id -g) $HOME/.kube/config
        ```        
    - C·∫•u h√¨nh ƒë·ªÉ c·∫£ 3 control-plane ƒë·ªÅu l√†m vi·ªác
        ```
        kubectl taint nodes k8s-master-1 node-role.kubernetes.io/control-plane:NoSchedule-
        kubectl taint nodes k8s-master-2 node-role.kubernetes.io/control-plane:NoSchedule-
        kubectl taint nodes k8s-master-3 node-role.kubernetes.io/control-plane:NoSchedule-
        ```
### 2.1.2. Cloud 
[Google Cloud console](https://cloud.google.com/cloud-console?utm_source=bing&utm_medium=cpc&utm_campaign=japac-VN-all-en-dr-bkws-all-pkws-trial-e-dr-1710102&utm_content=text-ad-none-none-DEV_c-CRE_-ADGP_Hybrid+%7C+BKWS+-+EXA+%7C+Txt+-Management+Tools-Cloud+Console-google+console-main-KWID_43700080475310202-kwd-71537784136902:loc-166&userloc_142907-network_o&utm_term=KW_console+google&gclid=41fd680d0d341fdaf6fa003bbd08b139&gclsrc=3p.ds&)
- Kh·ªüi t·∫°o c·ª•m K8s cloud
    - Kubenetes Engine -> Clusters -> Create (standard) 
    - Cluster basics: 
        - T√™n ƒë·∫∑t theo d·ª± √°n, theo m√¥i tr∆∞·ªùng
        - Location: ch·ªçn asian ƒë·ªÉ k·∫øt n·ªëi ·ªïn ƒë·ªãnh h∆°n 
        - Release channel: ch·ªçn k√™nh ph√°t h√†nh cho k8s trong c·ª•m, chi·∫øn l∆∞·ª£c ƒë·ªÉ n√¢ng c·∫•p c·ª•m k8s gi√∫p c√¢n b·∫±ng gi·ªØa t√≠nh kh·∫£ d·ª•ng c·ªßa c√°c t√≠nh nƒÉng m·ªõi v√† t√≠nh ·ªïn ƒë·ªãnh 
            Rapid: s·ª≠ d·ª•ng nh·ªØng t√≠nh nƒÉng m·ªõi c·∫£u GKE ngay khi v·ª´a ph√°t h√†nh -> 0 ·ªïn ƒë·ªãnh
            Regular: C√¢n b·∫±ng gi·ªØa t√≠nh nƒÉng v√† t√≠nh ·ªïn ƒë·ªãnh, c·∫≠p nh·∫≠t c√°c t√≠nh nƒÉng m·ªõi 1 c√°ch c√≥ ki·ªÉm so√°t (n√™n ch·ªçn)
            Stable: ph√π h·ª£p cho m√¥i tr∆∞·ªùng production c·∫ßn t√≠nh ·ªïn ƒë·ªãnh h∆°n t√≠nh nƒÉng m·ªõi
            Extended: Gi·ªØ nguy√™n phi√™n b·∫£n trong 1 th·ªùi gian d√†i  k·ªÉ c·∫£ khi n√≥ ƒë√£ b·ªã k·∫øt th√∫c th·ªùi gian h·ªó tr·ª£ chu·∫©n
            No channel: Kh√¥ng theo d√µi b·∫•t k√¨ channel n√†o v√† kh√¥ng t·ª± ƒë·ªông c·∫≠p nh·∫≠t -> g√¢y kh√≥ khƒÉn trong vc qu·∫£n l√Ω
    - Fleet registration: Cho ph√©p gom nh√≥m v√† qu·∫£n l√Ω c√°c c·ª•m k8s gi√∫p qu·∫£n l√Ω t·ª´ng c·ª•m ri√™ng l·∫ª sang qu·∫£n l√Ω theo nh√≥m -> T·∫≠n d·ª•ng kh·∫£ nƒÉng multi cluster (ƒëa c·ª•m) v√† √°p d·ª•ng c√°c policy nh·∫•t qu√°n tr√™n t·ªï ch·ª©c gi√∫p ƒë·ªìng nh·∫•t policy v√† v·∫≠n h√†nh 
    - default-pool: 
        - Compact placement: C√°c node s·∫Ω ƒë∆∞·ª£c c√†ng g·∫ßn nhau -> h·ªØu √≠ch gi√∫p t√¥i ∆∞u h√≥a t√†i nguy√™n tr√™n m√°y ch·ªß v·∫≠t l√Ω 
        - Queued ...: 
        - size: s·ªë l∆∞·ª£ng node, sl server 
        - automation: t·ª± ƒë·ªông n√¢ng c·∫•p c√°c node l√™n phi√™n b·∫£n c√≥ s·∫µn gi√∫p cho c√°c node theo c√°c phi√™n b·∫£n m·ªõi, t·ª± ƒë·ªçng b·∫≠t s·ª≠a ch·ªØa 
    - node pool upgrade strategy: Chi√™n l∆∞·ª£c c·∫≠p nh·∫≠t c·ªßa node
        - Surge update: b·ªï xung c√°c node khi ti·∫øn h√†nh c·∫≠p nh·∫≠t
        - Blue-green: pp t·∫°o c√°c node ho√†n to√†n m·ªõi v√† chuy·ªÉn sang c√°c node m·ªõi 
    - Nodes: Ch·ªçn c·∫•u h√¨nh server (ubuntu)
        - Machine config: c·∫•u h√¨nh ph·∫ßn c·ª©ng
    - Metadata:
        - k8s labels: g√°n nh√£n
            - env: development
    - Backup plane
    -> create 
# 3. Tri·ªÉn khai d·ª± √°n th·ª±c t·∫ø
## 3.1. Quy tr√¨nh ki·∫øn khai d·ª± √°n k8s
- V√≠ d·ª• quy tr√¨nh:

    ![Quy tr√¨nh](Images/image-2.png)

- H∆∞·ªõng nghi√™n c·ª©u t·ª´ node -> services -> Ingress (Ingress controller) -> traffic v√† h∆∞·ªõng ƒëi th√¨ ng∆∞·ª£c l·∫°i
### 3.1.1. Yaml trong k8s
- ∆Øu ƒëi·ªÉm: 
    - C√∫ ph√°p ƒë∆°n gi·∫£n (key: value)
    - ƒê·ªãnh d·∫°ng phong ph√∫
        - D·∫°ng list: th√™m d·∫•u - ·ªü tr∆∞·ªõc -> th√†nh 1 danh s√°ch 
    - C·∫•u tr√∫c r√µ r√†ng: l√πi v√†o ƒë√∫ng d√≤ng s·∫Ω th√†nh c·∫•u tr√∫c con
    - C·ªông ƒë·ªìng l·ªõn
- Th√†nh ph·∫ßn c·∫•u tr√∫c yaml:
    - apiVersion: v1, apps/v1, batch/v1
    - kind: thu·ªôc t√≠nh ƒë·ªÉ khai b√°o c√°c t√†i nguy√™n

        ![alt text](Images/image-3.png)
    - metadata: ch·ª©a c√°c th√¥ng tin li√™n quan ƒë·∫øn t√†i nguy√™n (t√™n, nh√£n, namespace)
    - spec: ƒê·ªãnh nghƒ©a chi ti·∫øt c·∫•u h√¨nh c·ªßa t√†i nguy√™n

        ![alt text](Images/image-4.png)
### 3.1.2. Namespace k8s
```
L√† 1 c√°ch t·ªï ch·ª©c v√† ph√¢n t√°ch c√°c t√†i nguy√™n trong 1 c·ª•m k8s ƒë·ªÉ qu·∫£n l√Ω t·ªët h∆°n. N√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ chia nh·ªè t√†i nguy√™n c·ªßa 1 c·ª•m l·ªõn th√†nh c√°c kh√¥ng gian l√†m vi·ªác logic nh·ªè h∆°n, gi√∫p d·ªÖ d√†ng qu·∫£n l√Ω v√† v·∫≠n h√†nh h∆°n.
```

![alt text](Images/image-5.png)

    Gi√∫p qu·∫£n l√Ω v√† ph√¢n chia t√†i nguy√™n 1 c√°ch r√µ r√†ng h∆°n khi c√≥ nhi·ªÅu nh√≥m l√†m vc tr√™n 1 c·ª•m d·ª±a tr√™n CPU, ram, ph√¢n t√°ch c√°c m√¥i tr∆∞·ªùng gi√∫p qu·∫£n l√Ω t·∫≠p trung v√† t·ªëi ∆∞u chi ph√≠, t√†i nguy√™n n√†y, ai ƒë∆∞·ª£c c·∫•u h√¨nh tr√™n n√≥

- M·∫∑c ƒëinh tr√™n k8s s·∫Ω c√≥ 1 c·ª•m m·∫∑c ƒë·ªãnh l√† default: 
    ```
    kubectl get pod --namespace default
    kubectl get ns
    ```
- T·∫°o 1  namespace ri√™ng ƒë·ªÉ cho 1 kh√¥ng gian ri√™ng cho d·ª± √°n sau ƒë√≥ x√≥a 
    ```
    kubectl create ns project-1
    kubectl delete ns project-1
    ```
- T·∫°o file yaml ƒë·ªÉ d·ªÖ c·∫•u h√¨nh v√† l∆∞u tr·ªØ

    ```
    mkdir projects
    cd projects
    mkdir project-1
    cd project-1
    vi ns.yaml

    apiVersion: v1
    kind: Namespace
    metadata:
        name: project-1

    √Åp d·ª•ng c·∫•u h√¨nh: 
    kubectl apply -f ns.yaml
    kubectl get ns

    X√≥a c·∫•u h√¨nh: 
    kubectl delete -f ns.yaml
    ```

- C·∫•u h√¨nh gi·ªõi h·∫°n t√†i nguy√™n cho namespace s·ª≠ d·ª•ng: `vi resourcequota.yaml`
    ```
    apiVersion: v1
    kind: ResourceQuota
    metadata: 
        name: mem-cpu-quota
        namespace: project-1
    spec: 
        hard:
            requests.cpu: "2"
            requests.memory: 4Gi
    
    kubectl apply -f resourcequota.yaml
    ```
## 3.2. T∆∞ duy tri·ªÉn khai d·ª± √° tr√™n Kubernetes
- ![alt text](Images/image-8.png)

## 3.3. C√°c c√¥ng c·ª• qu·∫£n l√Ω k8s 
- C√≥ 3 lo·∫°i ch√≠nh: command, desktop, website ƒë·ªÅu c√≥ ∆∞u, nh∆∞·ª£c ƒëi·ªÉm ri√™ng
- Search "k8s management tools"
- ∆Øu ti√™n c√¥ng ngh·ªá opensource: k9s, lens k8s, rancher 
## 3.4. C√†i ƒë·∫∑t Rancher v√† k·∫øt n·ªëi Kubernetes
    Rancher l√† 1 cc gi√∫p tri·ªÉn khai v√† qu·∫£n l√Ω v√† gi√°m s√°t nhi·ªÅu c·ª•m k8s tr√™n c√°c m√¥i tr∆∞·ªùng kh√°c nhau, bao g·ªìm On-premies v√† c√°c nh√† cc d·ªãch v·ª• ƒë√°m m√¢y nh∆∞ AWS, Azure, GG, ... 

### 3.4.1. Rancher l√†m ƒë∆∞·ª£c g√¨? 
- Qu·∫£n l√Ω nhi·ªÅu c·ª•m K8s
- Ph√¢n quy·ªÅn m·∫°nh m·∫Ω (Based RBAC K8s)
- H·ªó tr·ª£ gi√°m s√°t c·ª•m k8s
- B·∫£o m·∫≠t t·ªët
### 3.4.2. C√°c c√°ch c√†i ƒë·∫∑t
- C√≥ 2 c√°ch ch√≠nh: 
    - Ch·∫°y b·∫±ng docker thu·∫ßn
    - Ch·∫°y tr·ª±c ti·∫øp k8s
#### 3.4.2.1. Ch·∫°y b·∫±ng docker
- T·∫°o 1 server m·ªõi 1 processors, 2 Gi RAM, t·∫°o th√™m 1 ·ªï c·ª©ng v·ªõi 20Gi
    ```
    | rancher-server | 192.168.1.144 | rancher-server | 2GB | 1 | 20GB | 20GB | rancher.server.tech
    ```
    C·∫•u h√¨nh host, ip, hostname reboot 

- format ·ªï c·ª©ng sdb g√°n ·ªï c·ª©ng v√†o th∆∞ m·ª•c /data
    ```
    mkfs.ext4 -m 0 /dev/sdb
    mkdir /data
    echo "/dev/sdb /data ext4 defaults 0 0" | tee -a /etc/fstab
    
    cat /etc/fstab
    mount -a  
    df -h
    ```
- C√†i ƒë·∫∑t rancher b·∫±ng docker
    ```
    apt update 
    apt install docker.io
    apt install docker-compose
    ```
- Search "rancher version matrix" -> ch·ªçn phi√™n b·∫£n ph√π h·ª£p v·ªõi k8s 

    ```
    mkdir /data/rancher
    cd /data/rancher
    vi docker-compose.yml

    version: '3'
    services:
        rancher-server:
            image: rancher/rancher:v2.9.2
            container_name: rancher-server
            restart: unless-stopped
            ports:
                - "80:80"
                - "443:443"
            volumes:
                - /data/rancher/data:/var/lib/rancher   
            privileged: true


    docker-compose up -d
    docker ps -a 
    ```
- Truy c·∫≠p v√†o web rancher b·∫±ng ƒë·ªãa ch·ªâ ip c·ªßa rancher-server https://192.168.1.144
- L·∫•y m·∫≠t kh·∫©u Rancher v√† thi·∫øt l·∫≠p l·∫°i mk
    ```
    docker logs rancher-server 2>&1 | grep "Bootstrap Password:"
    ```
- N·ªëi c·ª•m k8s tr√™n rancher ƒë·ªÉ qu·∫£n l√Ω 
    - Ch·ªçn Import Exitsting c√≥ 2 l·ª±a ch·ªçn ch√≠nh: (ch·ªçn generic)

        ![alt text](Images/image-9.png)

    - Cluster Name: learnmyselfvn l√† c·ª•m k8s d·ª±ng n√™n, nh·∫±m m·ª•c ƒë√≠ch g√¨, ghi c·ª• th·ªÉ v√† t∆∞·ªùng minh 
    - Copy d√≤ng t·ª± k√Ω v√† sau khi t·∫£i v·ªÅ l·∫•y ƒë∆∞·ª£c 1 file yaml v√† apply file yaml ƒë√≥ v√† t√†i nguy√™n ƒë√£ ƒë∆∞·ª£c t·∫°o.

#### 3.4.2.2. C√†i ƒë·∫∑t tr√™n Rancher tr√™n Cloud (GCP)
- T·∫°o 1 VM ƒë·ªÉ c√†i rancher l√™n ƒë√≥
    - V√†o Compute engine -> VM Instance -> Create Instance
        ```
        Name: rancher-server
        Region: (asia-Tokyo)
        Zone: asia-..-c
        ```
    - Machine config: e2-medium 
    - OS and storage: Ubuntu - size 20Gi
        + add new disk: 20Gi
            - Name: disk-mount-data-rancher
            - Source: Blank
            - Size: 40Gi
    - Networks
        - Enable: http, https
- Sau khi ƒë√£ ho√†n t·∫•t th√¨ ssh v√†o v√† c·∫•u h√¨nh 
    - Update, c√†i ƒë·∫∑t docker, docker-compose
    - Ti·∫øn h√†nh mount disk r·ªóng ƒë√£ ƒë∆∞·ª£c t·∫°o tr∆∞·ªõc ƒë√≥ nh∆∞ ·ªü tr√™n 
        ```
        sudo mkfs.ext4 -m 0 /dev/sdb
        mkdir /data
        echo "/dev/sdb  /data  ext4  defaults  0  0" | sudo tee -a /etc/fstab
        mount -a
        sudo df -h
        ```
    - Docker run tr√™n server 
        ```
        docker run --name rancher-server -d --restart=unless-stopped -p 80:80 -p 443:443 -v /data/rancher:/var/lib/rancher --privileged rancher/rancher:v2.9.2
        ```
    - Sau ƒë√≥ truy c·∫≠p v√†o ƒë·ªãa ch·ªâ public ƒë√£ ƒë∆∞·ª£c c·∫•p, khi t·∫Øt m√°y th√¨ ƒë·ªãa ch·ªâ public n√†y se b·ªã thay ƒë·ªïi
    - Truy c·∫≠p v√†o vpc network -> ip addressses -> Reserver externel -> t·∫°o ra ƒë∆∞·ª£c 1 ƒë·ªãa ch·ªâ public ip v√† g√°n ƒë∆∞·ª£c v√†o m√°y ·∫£o
    - L·∫•y m·∫≠t kh·∫©u v√† v√†o trang ch√≠nh giao di·ªán
    
        ```
        docker logs  rancher-server  2>&1 | grep "Bootstrap Password:"
        ```

## 3.5. Pod K8s
    L√† ƒë∆°n v·ªã tri·ªÉn khai nh·ªè nh·∫•t v√† ƒë∆°n gi·∫£n nh·∫•t trong k8s 1 pod s·∫Ω ƒë·∫°i di·ªán cho 1 ho·∫∑c nhi·ªÅu container ƒë∆∞·ª£c nh√≥m l·∫°i v·ªõi nhau r·ªìi chia s·∫Ω t√†i nguy√™n c≈©ng nh∆∞ l√† m·∫°ng 
    M·ªói pod c√≥ m·ªôt ip ri√™ng c√≥ th·ªÉ hi·ªÉu  n√≥ nh∆∞ m·ªôt m√¥i tr∆∞·ªùng chia s·∫Ω ho·∫∑c l√† m√°y ch·ªß ·ª©ng d·ª•ng 

- Kh√¥ng n√™n ch·∫°y ƒë·ªôc l·∫≠p c√°c pod: 
    - Thi·∫øu kh·∫£ nƒÉng t·ª± ƒë·ªông kh√¥i ph·ª•c (self-healing) n√≥ s·∫Ω kh√¥ng t·ª± ƒë·ªông t·∫°o l·∫°i n·∫øu b·ªã l·ªói ho·∫∑c x√≥a 
    - Kh√¥ng qu·∫£n l√Ω ƒë∆∞·ª£c s·ªë l∆∞·ª£ng b·∫£n sao (replica): ch·∫°y ƒë·ªôc l·∫≠p ch·ªâ c√≥ 1 b·∫£n duy nh·∫•t n·∫øu mu·ªën ch·∫°y nhi·ªÅu b·∫£n ph·∫£i t·ª± t·∫°o th·ª≠ c√¥ng, kh√¥ng hi·ªáu qu·∫£ v√† d·ªÖ l·ªói 
    - Kh√¥ng h·ªó tr·ª£ c·∫≠p nh·∫≠t t·ª± ƒë·ªông(rolling update)
    - Kh√¥ng h·ªó tr·ª£ qu·∫£n l√Ω tr·∫°ng th√°i v√† l·ªãch s·ª≠ tri·ªÉn khai: kh√¥ng c√≥ l·ªãch s·ª≠ thay ƒë·ªïi, rollback hay phi√™n b·∫£n.
    - Thi·∫øu kh·∫£ nƒÉng t√≠ch h·ª£p c√°c c√¥ng c·ª• qu·∫£n l√Ω c√°o h∆°n: C√°c c√¥ng c·ª• CI/CD, auto-scaling, monitoring,... th∆∞·ªùng l√†m vi·ªác v·ªõi c√°c ƒë·ªëi t∆∞·ª£ng nh∆∞ Deployment ch·ª© kh√¥ng ph·∫£i Pod ƒë·ªôc l·∫≠p.

<div style="display: flex; justify-content: center; align-items: center;">
<img src="Images/image-12.png" alt="H√¨nh ·∫£nh"/>
</div>

### 3.5.1. Tri·ªÉn khai v√≠ d·ª• m·ªôt pod 
Quay l·∫°i k8s-master-1 server v√† t·∫°o ra th∆∞ m·ª•c project-1 b√™n trong /projects v√† truy c·∫≠p v√†o [docker hub](https://hub.docker.com/) t·∫°o th∆∞ m·ª•c ri√™ng v√† t·∫£i car-serv c·ªßa elroydevops v·ªÅ 

    cd projects/
    mkdir car-serv
    cd car-serv
vi ns.yaml
    
    apiVersion: v1 
    kind: Namespace
    metadata: 
        name: car-serv 
vi pod.yaml

    apiVersion: v1 
    kind: Pod
    metadata: 
        name: car-serv
        namespace: car-serv
    spec: 
        containers:
          - name: car-serv
            image: elroydevops/car-serv
            ports:
            - containerPort: 80
<br>
    
    kuberctl apply -f ns.yaml 
    kuberctl apply -f pod.yaml
    kublectl get pod -n car-serv

<br> Truy c·∫≠p v√†o b√™n trong m√¥i tr∆∞·ªùng container

    kubectl exec -it car-serv -n car-serv -- /bin/bash
    ls /usr/share
<h3>*Ch·ªâ n√™n tri·ªÉn khai 1 container tr√™n 1 pod ƒë·ªÉ gi·∫£m thi·ªÉu t·ªëi da s·ª± ph·ª• thu·ªôc

#### 3.5.1.1. C·∫•u h√¨nh ch·ªãu t·∫£i cho pod
    kubectl -get delete -f pod.yaml

## 3.6. Deployment k8s 
    Kh√¥ng n√™n ch·∫°y ƒë·ªôc l·∫≠p c√°c pod nh∆∞ ƒë√£ n√≥i ·ªü pod ta n√™n s·ª≠ d·ª•ng c√°c workload resource nh∆∞ Deployment ho·∫∑c Job ƒë·ªÉ ho·∫°t ƒë·ªông ƒë√∫ng c√°ch v√† ch·∫°y nhi·ªÅu pod.
    Khi s·ª≠ d·ª•ng Deployment ta c√≥ th·ªÉ ph√¢n b·ªï ƒë∆∞·ª£c bao nhi√™u pod ƒë∆∞·ª£c ch·∫°y ƒë·ªìng th·ªùi gi·ªëng nhau ƒë·∫£m b·∫£o ƒë∆∞·ª£c website ch·∫°y ·ªïn ƒë·ªãnh 
    L√† 1 ƒë·ªëi t∆∞·ª£ng ƒë·ªÉ qu·∫£n l√Ω pod, c√≥ th·ªÉ qu·∫£n l√Ω phi√™n b·∫£n ·ª©ng d·ª•ng, l∆∞u l·ªãch s·ª≠, scale ·ª©ng d·ª•ng, t·ª± d·ªông kh√¥i ph·ª•c l·ªói kh·ªüi t·∫°o l·∫°i 1 pod m·ªõi
### 3.6.1. V√≠ d·ª• m·ªôt file yaml Deployment ƒë∆°n gi·∫£n 
    apiVersion: apps/v1           # API version c·∫ßn thi·∫øt cho Deployment
    kind: Deployment              # Ki·ªÉu ƒë·ªëi t∆∞·ª£ng l√† Deployment
    metadata:
        name: nginx-deployment      # T√™n c·ªßa Deployment
        labels:
            app: nginx                # Nh√£n g·∫Øn cho Deployment (kh√¥ng b·∫Øt bu·ªôc)
    spec:
        replicas: 2                 # S·ªë l∆∞·ª£ng Pod mu·ªën ch·∫°y
        selector:
            matchLabels:
            app: nginx              # Deployment s·∫Ω qu·∫£n l√Ω c√°c Pod c√≥ label n√†y
        template:                   # M·∫´u ƒë·ªÉ t·∫°o c√°c Pod
            metadata:
                labels:
                    app: nginx            # Nh√£n g·∫Øn cho Pod (ph·∫£i kh·ªõp v·ªõi selector)
            spec:
            containers:
            - name: nginx           # T√™n container trong Pod
                image: nginx:1.25     # ·∫¢nh Docker ƒë·ªÉ ch·∫°y container
                ports:
                - containerPort: 80   # M·ªü c·ªïng trong container
---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
        labels:
            workload.user.cattle.io/workloadselector: apps.deployment-car-serv-car-serv-deployment
        name: car-serv-deployment
        namespace: car-serv
    spec:
        replicas: 2
        revisionHistoryLimit: 11
        selector:
            matchLabels:
                workload.user.cattle.io/workloadselector: apps.deployment-car-serv-car-serv-deployment
        template:
            metadata:
                labels:
                    workload.user.cattle.io/workloadselector: apps.deployment-car-serv-car-serv-deployment
                namespace: car-serv
            spec:
                containers:
                    - image: elroydevops/car-serv
                    imagePullPolicy: Always
                    name: car-serv
                    ports:
                        - containerPort: 80
                        name: tcp
                        protocol: TCP
    
- V·ªõi m√¥ h√¨nh ·ªü d∆∞·ªõi: 
    <div style="display: flex; justify-content: center; align-items: center;">
        <img src="Images/image-13.png" alt="H√¨nh ·∫£nh">
    </div> <br>

    ```
    Ta kh√¥ng th·ªÉ th·∫•y ƒë∆∞·ª£c deployment b·ªüi v√¨  ƒëi t·ª´ b√™n ngo√†i v√†o ch·ªâ x√°c ƒë·ªãnh ƒë∆∞·ª£c pod l√† g√¨, v√† service s·∫Ω l√†m vi·ªác v·ªõi deployment ƒë·ªÉ ƒë·∫£m b·∫£o chi·∫øn l∆∞·ª£c ƒë√≥ s·∫Ω ƒë·ªß pod v√† hi·ªáu qu·∫£ 
    ```

## 3.7. C√°c c√¢u l·ªánh Deployment K8s
- 
    | N·ªôi dung | C√¢u l·ªánh |
    |---|---|
    |L·∫•y danh s√°ch Deployment | `kubectl get deployment -n car-serv` |
    |L·∫•y danh s√°ch ReplicaSet | `kubectl get rs -n car-serv` |
    |Edit deployment|`kubectl edit deployment -n car-serv`|
    |Xem rollout status|`kubectl rollout status -n ...`|
    |C·∫≠p nh·∫≠t tr·ª±c ti·∫øp s·ªë l∆∞·ª£ng replicas|`kubectl scale deployment <ten-deployment> --replicas=<so-replicas> -n <ns>`|
    |Xem chi ti·∫øt c·ª• th·ªÉ v·ªÅ m·ªôt Deployment|`kubectl describe deployment -n <namespace>`|
    |Xem c·∫•u h√¨nh YAML c·ªßa m·ªôt Deployment|`kubectl get deployment <ten-deployment> -o yaml`|
    |C·∫≠p nh·∫≠t Deployment b·∫±ng c√°ch thay ƒë·ªïi h√¨nh ·∫£nh container|`kubectl set image deployment/<ten-deployment> <ten-container>=<ten-image>:<tag-moi>`|
    |Rollback Deployment v·ªÅ phi√™n b·∫£n tr∆∞·ªõc|`kubectl rollout undo deployment <ten-deployment>`|
    |Ki·ªÉm tra l·ªãch s·ª≠ c√°c phi√™n b·∫£n c·ªßa Deployment|`kubectl rollout history deployment <ten-deployment>`|
    |Li·ªát k√™ c√°c Pod ƒë∆∞·ª£c t·∫°o b·ªüi m·ªôt Deployment c·ª• th·ªÉ|`kubectl set env deployment/<ten-deployment> <key>=<value>`|
    |C·∫≠p nh·∫≠t bi·∫øn m√¥i tr∆∞·ªùng cho c√°c container trong Deployment|`kubectl set env deployment/<ten-deployment> <key>=<value>`|

- Auto scale: t·ª± ƒë·ªông tƒÉng gi·∫£m pod khi c√≥ s·ªë l∆∞·ª£ng truy c·∫≠p tƒÉng cao th√¨ h·ªá th·ªëng scale l√™n ho·∫∑c scale xu·ªëng 
- Pause, Resume: Gi√∫p ki·ªÉm so√°t ƒë∆∞·ª£c phi√™n b·∫£n tr∆∞·ªõc khi tri·ªÉn khai c√°c pod
## 3.8. C√°c chi·∫øn l∆∞·ª£c deployment k8s
- C√≥ 2 chi·∫øn l∆∞·ª£c tri·ªÉn khai ch√≠nh Rolling update v√† Recreate<br>
    ![alt text](Images/image-14.png)
    </br>
    ```
    Rolling Update: C·∫≠p nh·∫≠t l·∫ßn l∆∞·ª£t c√°c pod 
    Recreate: T·∫°o m·ªõi ho√†n to√†n c√°c pod
    ```
### 3.8.1. Rolling Update
```V√≠ d·ª•: Ta c√≥ 2 pod, khi tri·ªÉn khai version m·ªõi ch√∫ng ta thi·∫øt l·∫≠p 1 pod m·ªõi l√™n th√¨ x√≥a 1 pod c≈© ƒëi th√¨ ta s·∫Ω c√≥ 1 pod c≈© v√† 1 pod m·ªõi -> ƒë·∫£m b·∫£o d·ª± √°n ho·∫°t ƒë·ªông ƒë∆∞·ª£c``` 
- ƒê∆∞·ª£c √°p d·ª•ng trong h·∫ßu h·∫øt c√°c tr∆∞·ªùng h·ª£p
- Khi c·∫≠p nh·∫≠t version m·ªõi th√¨ version c≈© v·∫´n ƒëang ho·∫°t ƒë·ªông
- Chi·∫øn l∆∞·ª£c m·∫∑c ƒë·ªãnh kho 0 c·∫•u h√¨nh 

    ```
    Th√™m tr∆∞·ªùng strategy v√†o b√™n d∆∞·ªõi replicas

    strategy:
        type: RollingUpdate
    -> Th√™m d·∫ßn c√°c pop m·ªõi l√™n v√† x√≥a c√°c pod c≈©:
        rollingUpdate:
            maxSurge: L√† s·ªë l∆∞·ª£ng pod m·ªõi ƒë∆∞·ª£c ph√©p t·∫°o th√™m (v∆∞·ª£t qu√° s·ªë replicas ban ƒë·∫ßu) trong qu√° tr√¨nh c·∫≠p nh·∫≠t.

            maxUnavalilabe: L√† s·ªë l∆∞·ª£ng pod c≈© ƒë∆∞·ª£c ph√©p "m·∫•t" (t·∫°m d·ª´ng ho·∫∑c x√≥a) t·∫°i c√πng m·ªôt th·ªùi ƒëi·ªÉm trong qu√° tr√¨nh update.
    ....
    template:
        ....
        containers: 
        # image: elroydevops/car-serv
        image: nginx
    
    Sau ƒë√≥ import apply v√†o rancher 
    ```
- ƒê·ªÉ vi·ªác update ƒë∆∞·ª£c di·ªÖn ra th√¨ th∆∞·ªùng c·∫≠p nh·∫≠t image container, s·ª≠a file yaml,... 
### 3.8.2. Recreate
```V√≠ d·ª•: X√≥a to√†n b·ªô pod v√† kh·ªüi t·∫°o l·∫°i to√†n b·ªô pod```
- Tri·ªÉn khai nhanh
    ```
    Th√™m tr∆∞·ªùng strategy v√†o b√™n d∆∞·ªõi replicas

    strategy:
        type: Recreate
    ....
    template:
        ....
        containers: 
        # image: elroydevops/car-serv
        image: nginx
    
    Sau ƒë√≥ import apply v√†o rancher 
    ```
-> N√≥ s·∫Ω x√≥a to√†n b·ªô c√°c pod ƒëi v√† ti·∫øn h√†nh kh·ªüi t·∫°o n√™n pod m·ªõi -> Khi c·∫≠p nh·∫≠t th√¨ c√≥ th·ªÉ image c√≥ th·ªÉ r·∫•t n·∫∑ng th√¨ n√≥ s·∫Ω x·∫£y ra downtime
=> S·ª≠ d·ª•ng ch·∫°y job, ch·∫°y t√°c v·ª• clean data, clean version v√† t·∫°o version m·ªõi 
## 3.9. Services
L√† 1 ƒë·ªëi t∆∞·ª£ng d√πng ƒë·ªÉ ƒë·ªãnh nghƒ©a c√°ch ti·∫øp c·∫≠n ƒë·∫øn c√°c pod th∆∞·ªùng l√† 1 nh√≥m pod hay l√† vi·ªác tri·ªÉn khai c√°c pod qua deployment trong k8s

ƒê√≥ng vai tr√≤ ƒëi·ªÅu ph·ªëi traffic v√†o trong c√°c pod 
- C√≥ 4 lo·∫°i ch√≠nh 

    | Lo·∫°i | M·ª•c ƒë√≠ch | Truy c·∫≠p t·ª´ |
    | --- | --- | --- |
    | **ClusterIP (m·∫∑c ƒë·ªãnh)** | Cho ph√©p c√°c Pod **trong cluster** giao ti·∫øp v·ªõi nhau | N·ªôi b·ªô cluster |
    | **NodePort** | M·ªü c·ªïng tr√™n m·ªói Node ƒë·ªÉ truy c·∫≠p app t·ª´ **b√™n ngo√†i cluster** | T·ª´ b√™n ngo√†i (IP node + port) |
    | **LoadBalancer**         | T√≠ch h·ª£p v·ªõi cloud provider ƒë·ªÉ t·∫°o IP public                   | Truy c·∫≠p ngo√†i internet       |
    | **ExternalName**         | Tr·ªè ƒë·∫øn m·ªôt hostname b√™n ngo√†i cluster                         | D√πng DNS alias                |

- ClusterIP: t·∫°o c√°c IP cho ph√©p c√°c pod c√≥ th·ªÉ giao ti·∫øp n·ªôi b·ªô b√™n trong v√† b√™n ngo√†i kh√¥ng th·ªÉ giao ti·∫øp ƒë∆∞·ª£c, mu·ªën truy c·∫≠p ƒë∆∞·ª£c th√¨ ph·∫£i expose ra b√™n ngo√†i th√¥ng qua Ingress ho·∫∑c Gateway
- NodePort: m·ªü 1 port t·ª´ ·ª©ng d·ª•ng ra b√™n ngo√†i, truy c·∫≠p tr·ª±c ti·∫øp v√†o pod m√† kh√¥ng ƒëi qua b·∫•t k·ª≥ ƒë∆∞·ªùng n√†o.
- Loadbalancer: (D√†nh cho c√°c n·ªÅn t·∫£ng cloud) ƒêi·ªÅu ph·ªëi l∆∞u l∆∞·ª£ng ƒë·∫øn c√°c pod t∆∞∆°ng ·ª©ng, ph·∫£i ƒëi qua 1 c·ªóng n·ªØa r m·ªõi qua ƒë∆∞·ª£c k8s 
- ExtenalName: Lk v·ªõi 1 domain ·ªü b√™n ngo√†i, kh√¥ng t∆∞∆°ng t√°c vs k8s m√† t∆∞∆°ng t√°c vs domain

### 3.9.1. NodePort
#### 3.9.1.1. On-premit
- Range port c·ªßa service NodePort
    - Th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng d√£y port t·ª´ **30000-32767**
- S·ª≠ d·ª•ng NodePort
    - T·∫°o service ƒë·ªÉ truy c·∫≠p ƒë∆∞·ª£c v√†o t√†i nguy√™n 
    - Service Discovery -> Services -> Node Port 
    ```
    Name: car-serv-service 
    Portname: TCP
    Listening port: 80 
    Target port: 80
    Node port: 32000
    ```
    - Selector: Ch·ªâ ƒë·ªãnh deployment n√†o
    ```
    Key: app
    Values: ƒê·∫∑t tr√πng v·ªõi labels app: car-serv-deployment
    ```
- Th∆∞·ªùng kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng v√† ch·ªâ ƒë∆∞·ª£c sd khi export ·ª©ng d·ª•ng ra b√™n ngo√†i nhanh ch√≥ng ƒë·ªÉ c√≥ th·ªÉ debug, thu th·∫≠p th√¥ng tin,.. 
#### 3.9.1.2. On Cloud
- Truy c·∫≠p v√†o server v√† th·ª±c hi·ªán c√°c l·ªánh
    ```
    mkdir devops
    cd devops
    vi car-serv.yaml
    ```
    ```
    apiVersion: apps/v1
    kind: Deployment
    metadata:
        name: car-serv-deployment
        namespace: car-serv
    spec:
        selector:
            matchLabels: 
                app: car-serv
        replicas: 1
        template:
            metadata:
                labels:
                    app: car-serv
            spect:
                containers:
                  - name: car-serv
                    images: elroydepops/car-serv
                    ports:
                        - containerPort: 80
    ---
    apiVersion: v1
    kind: Services
    metadata:
        name: car-serv-service
        namespace: car-serv
    spec: 
        type: NodePort
        selector:
            app: car-serv
        ports:
          - protocols
            port: 80
            targetPort: 80
            nodePort: 32000
    ```
    T·∫°o namespace
    ```
    kubectl create ns car-serv
    kubectl apply -f car-serv.yaml
    ```
    L·∫•y to√†n b·ªô t√†i nguy√™n c·ªßa car-serv
    ```
    kubectl get all -n car-serv
    kubectl get node -o wide
    ```
    M·ªü Firewall:  Kube Engine -> VPC networks -> firewall -> create firewall rule
    ```
    Name: allow port 32000  
    target: All instance, ... 
    Source: 0.0.0.0/24
    Specified ...
        TCP: 32000 
    -> Create 
    ```

### 3.9.2. ClusterIP
- Kh·ªüi t·∫°o Service Discovery -> Services -> Create ClusterIP
`
Name: car-serv1-service
; PortName: tcp
; Listenning Port: 80
; Target Port: 80
`
- selectors: `Key: app; Value: car-serv-deployment`
## 3.10. Helm 
**Helm l√† tr√¨nh qu·∫£n l√Ω package cho k8s d√πng chart ƒë·ªÉ deploy ·ª©ng d·ª•ng ph·ª©c t·∫°p - t∆∞∆°ng t·ª± nh∆∞ apt trong ubuntu hay yum trong CentOS, nh∆∞ng d√†nh cho ·ª©ng d·ª•ng ch·∫°y trong k8s Gi√∫p t√°i s·ª≠ d·ª•ng YAML, c·∫•u h√¨nh linh ho·∫°t qua bi·∫øn**

### 3.10.1. M·ª•c ƒë√≠ch c·ªßa Helm
| T√≠nh nƒÉng                 | M√¥ t·∫£                                                           |
| ------------------------- | --------------------------------------------------------------- |
| üß≥ ƒê√≥ng g√≥i ·ª©ng d·ª•ng      | Helm d√πng c√°c **Chart** ƒë·ªÉ ƒë√≥ng g√≥i c·∫•u h√¨nh Kubernetes         |
| ‚öôÔ∏è T√°i s·ª≠ d·ª•ng & c·∫•u h√¨nh | Cho ph√©p t√°i s·ª≠ d·ª•ng YAML v·ªõi bi·∫øn ƒë·ªông cao, d·ªÖ t√πy ch·ªânh       |
| üß† Qu·∫£n l√Ω version        | Tri·ªÉn khai, n√¢ng c·∫•p, rollback phi√™n b·∫£n ·ª©ng d·ª•ng               |
| üìà Tri·ªÉn khai nhanh       | C√≥ th·ªÉ deploy 1 ·ª©ng d·ª•ng ph·ª©c t·∫°p ch·ªâ v·ªõi 1 l·ªánh `helm install` |

### 3.10.2. C·∫•u tr√∫c c·ªßa Helm Chart 
M·ªôt Helm Chart l√† m·ªôt th∆∞ m·ª•c ch·ª©a c√°c c√°i template:
```
mychart/
‚îú‚îÄ‚îÄ Chart.yaml        # Metadata c·ªßa chart (t√™n, version, m√¥ t·∫£...)
‚îú‚îÄ‚îÄ values.yaml       # Gi√° tr·ªã c·∫•u h√¨nh m·∫∑c ƒë·ªãnh (bi·∫øn)
‚îú‚îÄ‚îÄ templates/        # C√°c file YAML Kubernetes c√≥ th·ªÉ d√πng bi·∫øn
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ service.yaml
‚îÇ   ‚îî‚îÄ‚îÄ _helpers.tpl  # H√†m template ph·ª•
```

C√°ch ho·∫°t ƒë·ªông:
```
Vi·∫øt c√°c template YAML nh∆∞ deployment.yaml, service.yaml...
ƒê·ªãnh nghƒ©a c√°c gi√° tr·ªã (bi·∫øn) trong values.yaml
Khi ch·∫°y: `helm install myapp ./mychart` 
‚Üí Helm s·∫Ω render c√°c template v·ªõi gi√° tr·ªã, v√† t·∫°o t√†i nguy√™n Kubernetes t∆∞∆°ng ·ª©ng
```

### 3.10.3. M·ªôt s·ªë l·ªánh Helm c∆° b·∫£n

| L·ªánh               | T√°c d·ª•ng                      |
| ------------------ | ----------------------------- |
| `helm install`     | C√†i ·ª©ng d·ª•ng                  |
| `helm upgrade`     | N√¢ng c·∫•p ·ª©ng d·ª•ng             |
| `helm uninstall`   | G·ª° ·ª©ng d·ª•ng                   |
| `helm list`        | Li·ªát k√™ c√°c release ƒëang ch·∫°y |
| `helm repo add`    | Th√™m Helm repository          |
| `helm search repo` | T√¨m ·ª©ng d·ª•ng trong repo       |
| `helm template`    | Render YAML ra xem tr∆∞·ªõc      |
### 3.10.4. Helm Repo l√† g√¨?
> **Helm cho ph√©p b·∫°n s·ª≠ d·ª•ng c√°c Helm Chart ƒë√£ ƒë∆∞·ª£c vi·∫øt s·∫µn t·ª´ c·ªông ƒë·ªìng.**

- V√≠ d·ª•: 
    ```
    helm repo add bitnami https://charts.bitnami.com/bitnami
    helm install my-nginx bitnami/nginx
    ```
‚Üí Deploy nginx c·ª±c nhanh, c√≥ th·ªÉ custom qua --set ho·∫∑c -f values.yaml
### 3.10.5. L·ª£i √≠ch c·ªßa Helm
| ∆Øu ƒëi·ªÉm          | L·ª£i √≠ch th·ª±c t·∫ø                                           |
| ---------------- | --------------------------------------------------------- |
| T√°i s·ª≠ d·ª•ng      | 1 chart c√≥ th·ªÉ d√πng cho nhi·ªÅu m√¥i tr∆∞·ªùng                  |
| Qu·∫£n l√Ω config   | D·ªÖ ch·ªânh b·∫±ng `values.yaml` ho·∫∑c `--set`                  |
| Tri·ªÉn khai nhanh | Nhi·ªÅu ·ª©ng d·ª•ng l·ªõn (MySQL, Redis, Jenkins...) ƒë√£ c√≥ chart |
| Rollback d·ªÖ d√†ng | D·ªÖ tr·ªü l·∫°i version tr∆∞·ªõc n·∫øu l·ªói                        |

## 3.11. Ingress 
### 3.11.1. On-Premit
- T√†i nguy√™n qu·∫£n l√Ω c√°ch th·ª©c truy c·∫≠p t·ª´ b√™n ngo√†i v√†o services b√™n trong k8s
- Gi√∫p ƒëi·ªÅu h∆∞·ªõng l∆∞u l∆∞·ª£ng http/ https t·ªõi c√°c service n·ªôi b·ªô v√† th∆∞·ªùng th√¥ng qua m·ªôt ingress Controller (v√≠ d·ª•: NGINX Ingress Controller).
- Th·ª±c t·∫ø th∆∞·ªùng d√πng Nginx ingress, HAProxy, Kong Ingress Controller
#### 3.11.1.1. Th√†nh ph·∫ßn ch√≠nh c·ªßa Ingress:
- Ingress Resource (file YAML ƒë·ªãnh nghƒ©a ƒë∆∞·ªùng routing)
- Ingress Controller (ph·∫ßn m·ªÅm th·ª±c t·∫ø x·ª≠ l√Ω routing, v√≠ d·ª•: NGINX, Traefik, HAProxy, Contour...)
#### 3.11.1.2. C√†i ƒë·∫∑t v√† c·∫•u h√¨nh Nginx Ingress Controller 
- Search: `Nginx Ingress` -> `Installation` -> `Intall NGINX ...` -> `Install with Helm`
- Th√¥ng th∆∞·ªùng khi tri·ªÉn khai c√°c d·ª± √°n k8s ta hay c√≥ c√°c file deployment, services, ingress,... Thay v√¨ t·ª´ng d·ª± √°n ta ph·∫£i apply nh∆∞ v·∫≠y th√¨ ta ch·ªâ c·∫ßn ƒë√≥ng g√≥i th√†nh 1 template ƒë·∫ßy ƒë·ªß c√°c file deployment, services, ... sau n√†y khi tri·ªÉn khai d·ª± √°n ta ch·ªâ c·∫ßn l√¥i template n√†y ra v√† s·ª≠ d·ª•ng, ch·ªâ c·∫ßn thay ƒë·ªïi 1 s·ªë c√°c gi√° tr·ªã, port, t√™n, services,... 
- C√†i ƒë·∫∑t Helm: Search`Helm release`
- S·ª≠ d·ª•ng user root ·ªü master-1 
    ```
    wget https://get.helm.sh/helm-v3.16.2-linux-amd64.tar.gz
    tar xvf helm-v3.16.2-linux-amd64.tar.gz
    sudo mv linux-amd64/helm /usr/bin/
    helm version
    ```
- C√†i ƒë·∫∑t Ingress controller
    ```
    helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
    helm repo update
    helm search repo nginx
    helm pull ingress-nginx/ingress-nginx
    tar -xzf ingress-nginx-4.11.3.tgz
    ```
    `vi ingress-nginx/values.yaml`

    ![alt text](Images/image-type.png)
    ```
    S·ª≠a type: LoadBalancing => type: NodePort
    S·ª≠a nodePort http: "" => http: "30080"
    S·ª≠a nodePort https: "" => https: "30443"
    helm -n ingress-nginx install ingress-nginx -f ingress-nginx/values.yaml ingress-nginx
    ```
    
    ```
    NAME: ingress-nginx
    LAST DEPLOYED: Wed Jun 25 11:41:15 2025
    NAMESPACE: ingress-nginx
    STATUS: deployed
    REVISION: 2
    TEST SUITE: None
    NOTES:
    The ingress-nginx controller has been installed.
    Get the application URL by running these commands:
      export HTTP_NODE_PORT=30080
      export HTTPS_NODE_PORT=30443
      export NODE_IP="$(kubectl get nodes --output jsonpath="{.items[0].status.addresses[1].address}")"

      echo "Visit http://${NODE_IP}:${HTTP_NODE_PORT} to access your application via HTTP."
      echo "Visit https://${NODE_IP}:${HTTPS_NODE_PORT} to access your application via HTTPS."

    An example Ingress that makes use of the controller:
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: example
        namespace: foo
      spec:
        ingressClassName: nginx
        rules:
          - host: www.example.com
            http:
              paths:
                - pathType: Prefix
                  backend:
                    service:
                      name: exampleService
                      port:
                        number: 80
                  path: /
        # This section is only required if TLS is to be enabled for the Ingress
        tls:
          - hosts:
            - www.example.com
            secretName: example-tls

    If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided:

      apiVersion: v1
      kind: Secret
      metadata:
        name: example-tls
        namespace: foo
      data:
        tls.crt: <base64 encoded cert>
        tls.key: <base64 encoded key>
      type: kubernetes.io/tls

    ```
    * ·ªû m√¥i tr∆∞·ªùng cloud th√¨ type: Loadbancer c√≤n On-premit th√¨ type: NodePort
-> Sau khi ƒë√£ th√™m th√†nh c√¥ng ta copy c√°c d√≤ng ƒë∆∞·ª£c hi·ªÉn th·ªã 
#### 3.11.1.3. Tri·ªÉn khai loadbalancer
- Loadbalance: c√¢n b·∫±ng t·∫£i c√°c node pod c·ªßa k8s ƒëi ra b√™n ngo√†i client (Nginx ho·∫∑c HAProxy)
- T·∫°o 1 server loadbalance ri√™ng: **`|loadbalancer|192.168.1.110|loadbalancer-k8s|1GB|CPU 1|Disk 20|`** <br>

    ```
    ƒê·ªïi hostname: loadbalancer
    ƒê·ªãa ch·ªâ IP: 192.168.1.110
    sudo -i

    apt install nginx -y
    vi /etc/nginx/sites-available/default
    ƒê·ªïi port listen th√†nh port kh√°c 9999 ch·∫≥ng h·∫°n
    ```
    vi /etc/nginx/conf.d/devopsedu.vn.conf
    ```
    upstream my_servers {
    server 192.168.1.111:30080;
    server 192.168.1.112:30080;
    server 192.168.1.113:30080;
    }

    server {
        listen 80;
        hostname anphuc-onpremit.tech.vn;
        location / {
            proxy_pass http://my_servers;
            proxy_redirect off;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }

    sudo ln -s /etc/nginx/sites-available/anphuc.tech.vn.conf /etc/nginx/sites-enabled/
    nginx -t 
    systemctl restart nginx
    ```
- V√†o rancher truy c·∫≠p v√†o Ingresses -> Copy file yaml t·ª´ l√∫c c√†i ƒë·∫∑t Ingress controller 
    ```
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
      name: car-serv-ingress
      namespace: car-serv-ns
    spec:
      defaultBackend:
        service:
          name: car-serv-service
          port:
            number: 80
      ingressClassName: nginx
      rules:
        - host: anphuc-onpremit.tech.vn
          http:
            paths:
              - backend:
                  service:
                    name: car-serv-service
                    port:
                      number: 80
                path: /
                pathType: Prefix
    ```
- Add host tr√™n win 192.168.1.110 car-serv-onpre.devopsedu.vn
### 3.11.2. On Cloud
- X√≥a c√°c resource ƒë√£ kh·ªüi t·∫°o 
`kubectl delete -f car-serv.yaml`
- C√†i ƒë·∫∑t helm, c√†i ingress nginx 
    ```
    wget https://get.helm.sh/helm-v3.16.2-linux-amd64.tar.gz
    tar xvf helm-v3.16.2-linux-amd64.tar.gz
    sudo mv linux-amd64/helm /usr/bin/
    helm version
    ```
    ```
    helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
    helm repo update
    helm pull ingress-nginx/ingress-nginx
    tar -xzf ingress-nginx-4.11.3.tgz
    - Gi·ªØ nguy√™n c·∫•u h√¨nh type l√† loadbalancer tr√™n cloud
    kubectl create ns ingress-nginx
    helm -n ingress-nginx install ingress-nginx -f ingress-nginx/values.yaml ingress-nginx
    ```
- T·∫°o ra 1 file v·ªõi deployment car-serv-dp-sv-ig
    ```
    apiVersion: apps/v1
    kind: Deployment
    metadata:
        name: car-serv-deployment
        namespace: car-serv
    spec:
        selector:
            matchLabels: 
                app: car-serv
        replicas: 1
        template:
            metadata:
                labels:
                    app: car-serv
            spect:
                containers:
                  - name: car-serv
                    images: elroydepops/car-serv
                    ports:
                        - containerPort: 80
    ---
    apiVersion: v1
    kind: Services
    metadata:
        name: car-serv-service
        namespace: car-serv
    spec: 
        type: ClusterIP
        selector:
            app: car-serv
        ports:
          - protocols: TCP
            port: 80
            targetPort: 80
    ---
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
        name: car-serv-ingress
        namespace: car-serv
        annotations:
            kubernetes.io/ingress.class: "nginx"
    spec:
        rules:
            - host: car-serv-cloud.devopsedu.vn
            http:
                paths:
                - backend:
                    service:
                        name: car-serv1-service
                        port:
                        number: 80
                    path: /
                    pathType: Prefix
    ```
-> L∆∞u v√† Apply c·∫•u h√¨nh: `kubectl apply -f car-serv-dp-ig.yaml`
- V√†o tr√¨nh qu·∫£n l√Ω domain v√† tr·ªè domain v√†o c√°i public ip c·ªßa loadbalancer 
- Ti·∫øn h√†nh t√¨m ip ƒë·ªÉ tr·ªè t·ªõi: `kubectl get all -n car-serv`, `kubectl get ingress -n car-serv`-> address v√†o host
## 3.12. Template yaml 
- ·ªû c√°c ph·∫ßn tr√™n ta ƒë√£ tri·ªÉn khai ·ªü On-premit: deployment, services, Ingress -> download c√°c file c·∫•u h√¨nh n√†y v·ªÅ sau ƒë√≥ t·ªëi ∆∞u file t·∫•t c·∫£ ph·∫ßn n√†o l√† c·∫•u h√¨nh m·∫∑c ƒë·ªãnh nh∆∞ annoitaion, timestamp hay managerFied th√¨ s·∫Ω x√≥a b·ªè 
## 3.13. Tri·ªÉn khai d·ª± √°n Fullstack
### 3.13.1. M√¥ h√¨nh d·ª± √°n 
![alt text](Images/image-15.png)
```
Database: Mariadb 
Backend: java string boot api
Frontend: Angular
Tri·ªÉn khai ph∆∞∆°ng √°n fullstack v·ªõi backend c√≥ domain l√† api-ecommerce.networks.vn v√† frontend c√≥ domain l√† ecommerce.networks.vn c·∫ßn ph·∫£i c√≥ 1 server ƒë·ªÉ ch·ª©a database 
```
- T·∫°o ra 1 server: `|database|192.168.1.115|database-server|2GB|1|`

    ```
    apt update -y
    apt install mariadb-server
    vi /etc/mysql/mariadb.conf.d/50-server.cnf
    bind-add: 0.0.0.0
    systemctl restart mariadb
    ```
    
- T·∫£i file d·ª± √°n xu·ªëng 
    **N·∫øu mu·ªën ƒë·ªïi l·∫°i domain th√¨ h√£y t√¨m ki·∫øm trong th∆∞ m·ª•c c·ªßa d·ª± √°n t·∫•t c·∫£ c√°c domain "devopsedu.vn" v√† thay th·∫ø th√†nh domain m√† m√¨nh mu·ªën**
- Sau ƒë√≥ ti·∫øn h√†nh pull d·ª± √°n ƒë√≥ l√™n dockerhub ho·∫∑c registry, ƒë∆°n gi·∫£n h∆°n l√† chuy·ªÉn file d·ª± √°n ƒë√≥ v√†o trong server ƒë·ªÉ build sau khi chuy·ªÉn d·ª± √°n v√†o th∆∞ m·ª•c tmp th√¨ gi·∫£i n√©n v√† c√†i ƒë·∫∑t docker
    ```
    Tr√™n win: scp /file.zip ip@username:/tmp
    Tr√™n database-server linux:
        unzip file.zip 
        mkdir /projects
        cp /tmp/file.zip /projects
        apt install unzip -y
        apt install docker.io -y
    ```
#### 3.13.1.1. Frontend
- Di chuy·ªÉn ƒë·∫øn th∆∞ m·ª•c frontend v√† trong ƒë√≥ c√≥ ch·ª©a 1 Dockerfile build n√≥ l√™n 
    ```
    docker build -t ecommerce-frontend:v1 . 
    docker images
    ```
- Sau ƒë√≥ push l√™n dockerhub: 
    ```
    docker login
    docker tag ecommerce-frontend:v1 username/ecommerce-frontend:v1 
    docker images
    docker push
    ```
- V·ªõi c·∫•u tr√∫c file ƒë∆∞·ª£c build s·∫µn deployment, v√† c√°c ch·ª©c nƒÉng kh√°c ho√†n ch·ªânh ·ªü ph·∫ßn loadbancer ta l·∫•y v·ªÅ v√† thay ƒë·ªïi t√™n d·ª± √°n v√† t√™n docker images ƒë√£ push ·ªü tr√™n v·ªÅ v√† apply l·∫°i tr√™n rancher 
- T·∫°o Project ecommerce v√† namespace l√† ecommerce, nen t√°ch ra c√°c project nh·ªè gi·ªØa c√°c d·ª± √°n ƒë·ªÉ c√≥ th·ªÉ d·ªÖ d√†ng ph√¢n quy·ªÅn h∆°n 
- Import YAML m√† ƒë√£ s·ª≠a ·ªü tr√™n v√†o -> ki·ªÉm tra c√° gi√° tr·ªã -> Build th√†nh c√¥ng 
#### 3.13.1.2. Backend
- Tr·ªü l·∫°i database-server v√† di chuy·ªÉn v√†o th∆∞ m·ª•c 02-backend v√† v√†o file application.properties s·ª≠a c·∫•u h√¨nh ƒë·ªãa ch·ªâ ƒë√∫ng ƒë·∫øn database-server 192.168.1.115
- Ch·∫°y c√°c d·ªØ li·ªáu database tr∆∞·ªõc ƒë·ªÉ tr√°nh g·∫∑p l·ªói 
- V√†o l·∫°i th∆∞ m·ª•c 01 s·ª≠ d·ª•ng l·ªánh `pwd && ls` ƒë·ªÉ l·∫•y ch√≠nh x√°c c√°i path ƒë·ªÉ c·∫•u h√¨nh database 
    ```
    mysql 
    source ... (V·ªõi ƒë∆∞·ªùng d·∫´n ·ªü tr√™n v√† t·ª´ng file database)
    show tables
    ```
- Quay tr·ªü l·∫°i project 02-backend trong n√†y c√≥ s·∫µn 1 docker file 
    ```
    docker build -t ecommerce-backend:v1
    docker tag ecommerce-backend:v1 anphuc2370/ecommerce-backend:v1
    docker push username/ecommerce-backend:v1
    ```
- Sau khi push l√™n dockerhub ta quay l·∫°i file yaml s·ª≠a ch·ªØa v√† th√™m v√†o rancher
    ```
    ƒê·ªïi deployment t·ª´ frontend th√†nh backend
    S·ª≠a container port l√† 8080
    S·ª≠a domain: api-encommerce.anphuc.vn
    Apply tr√™n rancher ·ªü namespace ecommerce 
    ```
- Th√†nh c√¥ng
## 3.14. Configmaps
```
ConfigMap l√† m·ªôt ƒë·ªëi t∆∞·ª£ng API trong Kubernetes cho ph√©p l∆∞u tr·ªØ d·ªØ li·ªáu c·∫•u h√¨nh kh√¥ng nh·∫°y c·∫£m d∆∞·ªõi d·∫°ng c·∫∑p key-value. 
ƒêi·ªÅu n√†y gi√∫p t√°ch bi·ªát c·∫•u h√¨nh m√¥i tr∆∞·ªùng kh·ªèi h√¨nh ·∫£nh container, l√†m cho ·ª©ng d·ª•ng d·ªÖ d√†ng di chuy·ªÉn v√† qu·∫£n l√Ω h∆°n.
```
### 3.14.1. M·ª•c ƒë√≠ch s·ª≠ d·ª•ng ConfigMap
- T√°ch bi·ªát c·∫•u h√¨nh kh·ªèi m√£ ngu·ªìn: Gi√∫p qu·∫£n l√Ω c·∫•u h√¨nh m√¥i tr∆∞·ªùng ri√™ng bi·ªát, tr√°nh vi·ªác ph·∫£i ch·ªânh s·ª≠a v√† rebuild l·∫°i h√¨nh ·∫£nh container khi c√≥ thay ƒë·ªïi v·ªÅ c·∫•u h√¨nh.
- Qu·∫£n l√Ω c·∫•u h√¨nh cho nhi·ªÅu m√¥i tr∆∞·ªùng: D·ªÖ d√†ng t·∫°o v√† √°p d·ª•ng c√°c c·∫•u h√¨nh kh√°c nhau cho c√°c m√¥i tr∆∞·ªùng nh∆∞ ph√°t tri·ªÉn, ki·ªÉm th·ª≠ v√† s·∫£n xu·∫•t.
### 3.14.2. C√°ch t·∫°o v√† s·ª≠ d·ª•ng ConfigMap
- T·ª´ file ho·∫∑c th∆∞ m·ª•c:
`kubectl create configmap my-config --from-file=path/to/directory/`
- L·ªánh n√†y s·∫Ω t·∫°o m·ªôt ConfigMap v·ªõi m·ªói file trong th∆∞ m·ª•c ƒë∆∞·ª£c chuy·ªÉn th√†nh m·ªôt c·∫∑p key-value, trong ƒë√≥ key l√† t√™n file v√† value l√† n·ªôi dung file. 
- C√∫ ph√°p yaml c√≥ 2 c√°ch: 
  - C√°ch 1: S·ª≠ d·ª•ng c·∫•u tr√∫c key v√† value 
    ```
    data:
        # property-like keys; each key maps to a simple value
        player_initial_lives: "3"
        ui_properties_file_name: "user-interface.properties"
    ```
  - C√°ch 2: Khai b√°o d∆∞·ªõi d·∫°ng file
    ```
    data:
        # file-like keys
        game.properties: (t√™n file)|
            enemy.types=aliens,monsters
            player.maximum-lives=5    
        user-interface.properties: |
            color.good=purple
            color.bad=yellow
            allow.textmode=true  
    ```
- S·ª≠a l·∫°i dockerfile ·ªü backend v√¨ ch∆∞a ch·ªâ ƒë·ªãnh b·∫•t c·ª© m·ªôt c·∫•u h√¨nh n√†o ƒë·ªÉ ƒë·ªçc ƒë∆∞·ª£c file n√™n m·∫∑c ƒë·ªãnh n√≥ s·∫Ω l·∫•y file g·ªëc trong th∆∞ m·ª•c c·ªßa d·ª± √°n
- C·∫ßn ph·∫£i ch·ªâ ƒë·ªãnh ƒë·∫øn file config trong container 
    ```
    ENTRYPOINT java ... --spring.config.location=/run/src/main/resources/application.properties
    ```
- T·∫°o 1 configmaps v·ªõi n·ªôi dun file v√† c·∫•u h√¨nh c·ªßa application.properties v√† map v√†o ƒë∆∞·ªùng d·∫´n tr√™n ·ªü container th√¨ l√∫c ƒë√≥ d·ª± √°n backend c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c file c·∫•u h√¨nh
- L∆∞u l·∫°i v√† build l·∫°i file c·∫•u h√¨nh v√† ch·ª´ng sau s·∫Ω ch·ªâ c·∫ßn c·∫•u h√¨nh l·∫°i ·ªü tr√™n configmaps th√¥i kh√¥ng c·∫ßn build l·∫°i dockerfile 
    ```
    docker images 
    docker build -t username/ecommerce-backend:v2 .
    docker push username/ecommerce-backend:v2
    ```
- Quay l·∫°i rancher v√† t·∫°o t√†i nguy√™n configmaps 
    ```
    apiVersion: v1
    kind: ConfigMap
    metadata:
        name: ecommerce-backend-application-properties-configmap
        namespace: ecommerce
    data: 
        application.properties: |
            spring.datasource.url=jdbc:mysql://192.168.1.115:3306/full-stack-ecommerce #ch√∫ √Ω thay ƒë·ªïi ƒë·ªãa ch·ªâ IP c·ªßa b·∫°n 
            spring.datasource.username=ecommerceapp
            spring.datasource.password=StrongPa55WorD
            spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver
            spring.datasource.sql-script-encoding=UTF-8

            spring.jpa.properties.hibernate.globally_quoted_i/dentifiers=true
            spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect
            spring.jpa.hibernate.ddl-auto=none
            spring.jpa.show-sql=true
            spring.jpa.properties.hibernate.format_sql=true

            spring.data.rest.base-path=/api
            spring.data.rest.detection-strategy=ANNOTATED

            allowed.origins=http://ecommerce.devopsedu.vn

            okta.oauth2.client-id=0oab0lzwjoN1Rjsar5d7
            okta.oauth2.issuer=https://dev-82108115.okta.com/oauth2/default
    ```
- V√†o Storage Configmaps v√† ch·ªçn ƒë√∫ng namespace ƒë·ªÉ hi·ªÉn th·ªã r√µ
- Sau khi t·∫°o xong th√¨ ph·∫£i mount configmaps v√†o d·ª± √°n r·ªìi thay ƒë·ªïi docker images 
- Khai b√°o volumes th·∫≥ng v·ªõi container t√™n v√† volumeMounts: th·∫≥ng v·ªõi image : khai b√°o t√™n gi·ªëng v·ªõi volumes v√† mountPath l√† ƒë∆∞·ªùng d·∫´n ƒë∆∞·ª£c mount v√†o container 
- Edit yaml deployment
    ```
    spec:
        containers:
          - image: ...
            volumeMounts: 
                - mountPath: /run/src/main/resources/application.properties
                name: ecommerce-backend-application-properties-config-volume
                subPath: application.properties
        volumes:
          - configMap:
                defaultMode: 420
                name: ecommerce-backend-application-properties-configmap
          - name: ecommerce-backend-application-properties-config-volume
    ```
- ƒê·∫ßu ti√™n c·∫ßn t·∫°o 1 volume ƒë·ªÉ c√≥ 1 v·ªã tr√≠ l∆∞u tr·ªØ d·ªØ li·ªáu c·ªßa configmaps 
- Ti·∫øp theo trong container m√¨nh s·∫Ω t·∫°o ra 1 volume mount n√≥ s·∫Ω mount gi√° tr·ªã c·ªßa volume m√† m√¨nh v·ª´a t·∫°o v√†o b√™n trong container ƒë√≥ ·ªü trong th∆∞ m·ª•c /run/src/main/resources/application.properties 
- V√†o deployment th·ª≠ execute ƒë·ªÉ ki·ªÉm tra xem th·ª≠ c√≥ file ƒë√≥ ch∆∞a 
- Khi c·∫≠p nh·∫≠t c·∫•u h√¨nh m·ªõi th√¨ m√¨nh c·∫ßn redeploy l·∫°i v√† update image l·∫°i l√™n v2
### 3.14.3. L∆∞u √Ω 
- Kh√¥ng s·ª≠ d·ª•ng ConfigMap cho d·ªØ li·ªáu nh·∫°y c·∫£m: ConfigMap kh√¥ng ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ l∆∞u tr·ªØ th√¥ng tin nh·∫°y c·∫£m nh∆∞ m·∫≠t kh·∫©u, kh√≥a API. ƒê·ªëi v·ªõi d·ªØ li·ªáu nh·∫°y c·∫£m, h√£y s·ª≠ d·ª•ng ƒë·ªëi t∆∞·ª£ng Secret c·ªßa Kubernetes.
- Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc: D·ªØ li·ªáu trong ConfigMap kh√¥ng n√™n v∆∞·ª£t qu√° 1 MiB. N·∫øu c·∫ßn l∆∞u tr·ªØ c·∫•u h√¨nh l·ªõn h∆°n, h√£y xem x√©t s·ª≠ d·ª•ng volume ho·∫∑c d·ªãch v·ª• l∆∞u tr·ªØ b√™n ngo√†i. 
- C·∫≠p nh·∫≠t ConfigMap: Khi ConfigMap ƒë∆∞·ª£c c·∫≠p nh·∫≠t, c√°c container s·ª≠ d·ª•ng n√≥ th√¥ng qua volume s·∫Ω t·ª± ƒë·ªông nh·∫≠n ƒë∆∞·ª£c thay ƒë·ªïi. Tuy nhi√™n, ƒë·ªëi v·ªõi c√°c bi·∫øn m√¥i tr∆∞·ªùng, c·∫ßn ph·∫£i kh·ªüi ƒë·ªông l·∫°i Pod ƒë·ªÉ √°p d·ª•ng c·∫•u h√¨nh m·ªõi. 
## 3.15. Secret
- L√† ƒë·ªëi t∆∞·ª£ng k8s d√πng ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu nh·∫°y c·∫£m nh∆∞: m·∫≠t kh·∫©u, token, ssh-key, ch·ª©ng ch·ªâ tls
- Thay v√¨ l∆∞u tr·ª±c ti·∫øp v√†o c·∫•u h√¨nh pod, gi√∫p b·∫£o v·ªá th√¥ng tin nh·∫°y c·∫£m v√† qu·∫£n l√Ω d·ªÖ h∆°n.
- M√£ h√≥a b·∫±ng base64 ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu ƒë∆∞·ª£c truy·ªÅn qua kh√¥ng b·ªã l·ªói ƒë·ªãnh d·∫°ng
### 3.15.1. C√°c lo·∫°i secret ph·ªï bi·∫øn 

| Built-in Type	| Usage |
|---|---|
| Opaque	| arbitrary user-defined data (l∆∞u tr·ªØ d∆∞·ªõi d·∫°ng key-value) base64 | 
| kubernetes.io/service-account-token	| ServiceAccount token (X√°c th·ª±c account) | 
| kubernetes.io/dockercfg	| serialized ~/.dockercfg file (L∆∞u tr·ªØ nh·ªØng th√¥ng tin ƒëƒÉng nh·∫≠p c·ªßa docker registry nh∆∞ username, password, token )| 
| kubernetes.io/dockerconfigjson	| serialized ~/.docker/config.json file (L∆∞u tr·ªØ nh·ªØng th√¥ng tin ƒëƒÉng nh·∫≠p c·ªßa docker registry nh∆∞ username, password, token) d∆∞·ªõi d·∫°ng json | 
| kubernetes.io/basic-auth	| credentials for basic authentication (Ch·ª©a 2 lo·∫°i gi√° tr·ªã) |
| kubernetes.io/ssh-auth	| credentials for SSH authentication | 
| kubernetes.io/tls	| data for a TLS client or server (L∆∞u tr·ªØ ch·ª©ng ch·ªâ) |
| bootstrap.kubernetes.io/token |	bootstrap token data (L∆∞u tr·ªØ token bootstrap ƒë∆∞·ª£c s·ª≠ d·ª•ng khi mu·ªën th√™m 1 k8s cluster) |

### 3.15.2. C√°ch s·ª≠ d·ª•ng 
- Opaque
    ```
    apiVersion: v1
    kind: Secret
    metadata: 
        name: ecommerce-backend-database-connection
        namespace: ecommerce
    type: Opaque
    * C√≥ 2 c√°ch s·ª≠ d·ª•ng ·ªü ƒë√¢y 
    C√°ch 1: l√† nh·∫≠p data v√† c√°i key ph·∫£i ƒë∆∞·ª£c m√£ h√≥a tr∆∞·ªõc v·ªõi base64 
    C√°ch 2: l√† s·ª≠ d·ª•ng stringData ghi gi√° tr·ªã ch√≠nh x√°c, khi k8s s·ª≠ l√Ω s·∫Ω chuy·ªÉn sang d·∫°ng m√£ h√≥a 
    stringData:
        MARIADB_HOST: "192.168.1.115"
        MARIADB_DB: "full-stack-ecommerce"
        MARIADB_PORT: '3306'
        MARIADB_USERNAME: "ecommerceapp"
        MARIADB_PASSWORD: "StrongPa55WorD"
    ```
- Sau ƒë√≥ c·∫ßn ph·∫£i mount secret v√†o deployment nh∆∞ mapconfig (S·ª≠a b·∫±ng file yaml ho·∫∑c giao di·ªán rancher)
- S·ª≠a tr√™n giao di·ªán (edit ) -> Enviroment Variables -> Secret -> file -> Save 
- Excuse v√†o trong container v√† ki·ªÉm tra xem c√°c gi√° tr·ªã ƒë√£ ƒë∆∞·ª£c truy·ªÅn v√†o hay ch∆∞a 
- V√†o l·∫°i configmap ch·ªânh s·ª≠a l·∫°i c√°c th√¥ng s·ªë 
    ```
    HOST, PORT, DB
    USERNAME, PASSWORD
    Sau ƒë√≥ redepoy l·∫°i
    ```

* N·∫øu s·ª≠ d·ª•ng Docker private Registry (Harbor)

- Step 0. ƒê·∫£m b·∫£o ƒë√£ c√†i ƒë·∫∑t Harbor nh∆∞ trong link h∆∞·ªõng d·∫´n.
- Step 1. C·∫•u h√¨nh x√°c th·ª±c
T·∫°o secret ch·ª©a th√¥ng tin x√°c th·ª±c Harbor (Th·ª±c hi·ªán tr√™n server k8s-master-1 ho·∫∑c kubectl shell rancher)
    ```
    # kubectl create secret docker-registry auth-registry --docker-email=yourmail@gmail.com --docker-username=username-harbor --docker-password=password-harbor --docker-server=domain-harbor.com --namespace ecommerce
    ```
- Step 2: Th√™m secret v√†o Deployment
    ```
    apiVersion: apps/v1
    kind: Deployment
    metadata:
        name: your-deployment
        namespace: your-namespace
    spec:
        replicas: 1
        selector:
            matchLabels:
            app: your-app
        template:
            metadata:
                labels:
                    app: your-app
            spec:
                containers:
                - name: your-container
                    image: harbor-domain.com/devopseduvn/ecommerce-backend:v1
                imagePullSecrets:
                - name: auth-registry # th√™m t√™n secret nh∆∞ th·∫ø n√†y
    ```
## 3.16. Request v√† limit 
Request: y√™u c·∫ßu t√†i nguy√™n ƒë·∫°i di·ªán cho t√†i nguy√™n t·ªëi thi·ªÉu m√† container c·∫ßn ƒë·ªÉ ch·∫°y ·ªïn ƒë·ªãnh, S·ªë t√†i nguy√™n m√† k8s d√†nh ri√™ng ƒë·ªÉ ƒë·∫£m b·∫£o container lu√¥n lu√¥n c√≥ th·ªÉ ch·∫°y
Limit: l∆∞·ª£ng t√†i nguy√™n t·ªëi ƒëa m√† k8s ƒë∆∞·ª£c ph√©p s·ª≠ d·ª•ng 
### 3.16.1. M·ª•c ƒë√≠ch:
ƒê·∫£m b·∫£o container c√≥ ƒë·ªß t√†i nguy√™n ƒë·ªÉ ho·∫°t ƒë·ªông.
Tr√°nh vi·ªác container chi·∫øm d·ª•ng qu√° nhi·ªÅu t√†i nguy√™n, ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c container kh√°c.
### 3.16.2. Kh√°c bi·ªát

![alt text](Images/image-16.png)
### 3.16.3. C√°c lo·∫°i t√†i nguy√™n ch√≠nh
- CPU:
    - ƒê∆∞·ª£c ƒëo b·∫±ng ƒë∆°n v·ªã cores (nh√¢n CPU).
    - C√≥ th·ªÉ s·ª≠ d·ª•ng gi√° tr·ªã th·∫≠p ph√¢n (v√≠ d·ª•: 0.5 = 500m ‚Äì millicores).
    - Kubernetes s·ª≠ d·ª•ng CPU shares (c∆° ch·∫ø Cgroups) ƒë·ªÉ ph√¢n b·ªï CPU.
- B·ªô nh·ªõ (Memory):
    - ƒê∆∞·ª£c ƒëo b·∫±ng bytes (c√≥ th·ªÉ d√πng ƒë∆°n v·ªã Mi, Gi, Ki).
    - V√≠ d·ª•: 256Mi = 256 mebibytes, 1Gi = 1 gibibyte.
    - Kubernetes d√πng cgroup ƒë·ªÉ gi·ªõi h·∫°n b·ªô nh·ªõ.

## 3.17. HPA (autoscale)
- L√†m sao d·ª± √°n c√≥ kh·∫£ nƒÉng ch·ªãu t·∫£i v√† t√≠nh ·ªïn ƒë·ªãnh c·ªßa d·ª± √°n c≈©ng nh∆∞ l√†m th·∫ø n√†o ƒë·ªÉ gi√∫p d·ª± √°n c√≥ th·ªÉ tƒÉng gi·∫£m t√†i nguy√™n khi m√† l∆∞·ª£ng traffic bi·∫øn ƒë·ªông 
- Scale l√† qu√° tr√¨nh m·ªü r·ªông hay thu nh·ªè t√†i nguy√™n c·ªßa h·ªá th·ªëng ƒë·ªÉ ƒë√°p ·ª©ng ƒë∆∞·ª£c t·ªët h∆°n nhu c·∫ßu s·ª≠ d·ª•ng khi l∆∞u l∆∞·ª£ng ho·∫∑c kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác tƒÉng ho·∫∑c gi·∫£m 
- Nh·ªØng t√°c nh√¢n l√†m cho d·ª± √°n b·ªã ch·∫≠m th∆∞·ªùng ƒë·∫øn t·ª´ CPU, RAM, Network, Loadbance, ...
- C√≥ 2 lo·∫°i ch√≠nh (Vertial Scaling v√† Horizontal Scaling)
  - TƒÉng theo chi·ªÅu d·ªçc (Vertial Scaling): TƒÉng gi·∫£m CPU, memory 
  - TƒÉng Theo chi·ªÅu ngang (Horizontal Scaling): Th√™m s·ªë l∆∞·ª£ng intance, pod (HPA)
### 3.17.1. Horiontal Pod Autoscaler (HPA)
- D·ª±a theo 2 t√†i nguy√™n: CPU v√† memory 
- V√≠ d·ª• ·ªü pod d·ª± √°n backend khi n√†o l∆∞·ª£ng truy c·∫≠p v∆∞·ª£t qu√° 80% c·ªßa limit th√¨ l√∫c ƒë√≥ s·∫Ω ti·∫øn h√†nh scale ra c√°c pod kh√°c v√† set gi√° tr·ªã min v√† max c·ªßa pod 
- C·∫ßn tinh ch·ªânh k·ªπ v√¨ c√≥ khi s·ª≠ d·ª•ng autoscale n√≥ s·∫Ω ki·ªÉm tra memory ho·∫∑c CPU n√≥ s·∫Ω ti·∫øn h√†nh th√™m c√°c pod m·ªõi d·ªÖ b·ªã tƒÉng qu√° nhanh pod c√≥ th·ªÉ b·ªã over resource 
### 3.17.2. Metric Server 
- C√¥ng c·ª• thu th·∫≠p t√†i nguy√™n c·ªßa pod ƒë·ªÉ ƒë√°nh gi√° ƒë∆∞·ª£c pod ƒëang s·ª≠ d·ª•ng (Metric Server) [Metric Server Git](https://github.com/kubernetes-sigs/metrics-server)

- C√†i ƒë·∫∑t b·∫±ng helm tr√™n k8s (master-1)
    ```
    helm repo add  metric-server https://kubernetes-sigs.github.io/metrics-server/
    helm pull metric-server/metrics-server
    tar -xvf metrics-server-*
    helm install metric-server metrics-server -n kube-system
    ```
- S·ª≠a deployment c·ªßa kube-system
    ```
    spec:
        containers:
            - args:
                **ƒê·ªïi t·∫•t c·∫£ port 1110 -> 4443**
                '--secure-port-4443'
                -'--kubelet-insecure-tls-true'
    ```
- Ki·ªÉm tra nhanh: 
    ```
    kubectl top nodes 
    kubectl top pod -n ecommerce
    ```
- HPA tr√™n giao di·ªán ·ªü trong Service Discovery -> HPA
- T·∫°o HPA b·∫±ng file c·∫•u h√¨nh
    ```
    apiVersion: autoscaling/v1
    kind: HoriontalPodAutoscaler
    metadata:
        name: ecommerce-backend-autoscaling
        namespace: ecommerce
    spec:
        scaleTargetRef:
            apiVersion: apps/v1
            kind: deployment
            name: ecommere-backend-deployment
        minReplicas: 2
        maxReplicas: 4
        targetCPUUtilizationPercentage: 50
    ```
    > ƒê·ªãnh nghƒ©a: 
    > - scaleTargetRef: Thu·ªôc t√≠nh x√°c ƒë·ªãnh theo d√µi, gi√°m s√°t t√†i nguy√™n n√†o
    > - targetCPUUtilizationPercentage: Ch·ªâ ƒë·ªãnh gi√° tr·ªã n√†o v∆∞·ª£t ng∆∞·ª°ng th√¨ ti·∫øn h√†nh scale l√™n 
- Test h·ªá th·ªëng b·∫±ng c√°ch stress 
excuse v√†o pod sau ƒë√≥ c√†i ƒë·∫∑t stress
    ```
    apk update
    apk add stress-ng
    stress-ng --cpu 1
    stress
    ```
## 3.18. S·ª≠ d·ª•ng Rancher 
## 3.19. S·ª≠ d·ª•ng RBAC Rancher 
- Role-based access control(RBAC): ƒê·ªÉ ph√¢n quy·ªÅn ƒë∆∞·ª£c ch√≠nh x√°c 
- Tr√™n Rancher:
  - Users and Authentication: T·∫°o user v√† thi·∫øt l·∫≠p quy·ªÅn cho user
  - Global Permisions
    - Admin: to√†n quy·ªÅn
    - Restriced Admin: Full control ·ªü c√°c t√†i nguy√™n cluster nh∆∞ng m√† kh√¥ng ƒëc access ·ªü c√°i local 
    - Standard User: T·∫°o user m·ªõi v√† qu·∫£n l√Ω cluster c√°c project m√† ƒë∆∞·ª£c g√°n quy·ªÅn (Th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong 1 team)
- Sau ƒë√≥ v√†o role templates ƒë·ªÉ g√°n quy·ªÅn 
    - Owner ho·∫∑c memmber
    - Custom: c√°c role c√≥ s·∫µn ·ªü template ho·∫∑c t·∫°o th√™m c√°c quy·ªÅn

# 4. X√¢y d·ª±ng c√¥ng c·ª• d·ª± √°n 
## 4.1. Tri·ªÉn khai c√¥ng c·ª•
- C√°c c√¥ng c·ª• database
- V·ªõi d·ª± √°n nh·ªè th√¨ n√™n tri·ªÉn khai tr·ª±c ti·∫øp l√™n server 
## 4.2. StorageClass
- ƒê·ªÉ tri·ªÉn khai c√°c c√¥ng c·ª• nh∆∞ database, cache,... ta c·∫ßn ph·∫£i c√≥ m·ªôt n∆°i ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu
- L∆∞u tr·ªØ d·ª± li·ªáu tr√™n k8s ntn? 
- Seach `How to manage storage on k8s`
  - C√≥ c√°c keywork ch√≠nh PV, PVC v√† StorageClasses
  ![alt text](Images/storage-manager.png)
- L√† 1 ƒë·ªëi t∆∞·ª£ng gi√∫p ƒë·ªãnh nghƒ©a c√°c lo·∫°i l∆∞u tr·ªØ kh√°c nhau VD: "Ti·ªám b√°nh: gi·ªëng nh∆∞ c√°c lo·∫°i kho h√†ng kh√°c nhau ·ªü trong ti·ªám b√°nh ƒë·ªÉ l∆∞u tr·ªØ b√°nh v√† c√°c v·∫≠t ph·∫©m li√™n quan t√πy v√†o t√≠nh ch·∫•t c·ªßa t·ª´ng lo·∫°i kho nh∆∞ `Kho l·∫°nh: d√πng ƒë·ªÉ l∆∞u tr·ªØ c√°c lo·∫°i b√°nh l·∫°nh, b√°nh kem c·∫ßn nhi·ªát ƒë·ªô th·∫•p` hay `Kho kh√¥: l∆∞u tr·ªØ c√°c lo·∫°i b√°nh kh√¥, b√°nh m√¨`"
-  Storageclass l√† t√†i nguy√™n to√†n c·ª•c (t√†i nguy√™n trong to√†n b·ªô h·ªá th·ªëng tr√™n c·ª•m Kubernetes) n√™n kh√¥ng c·∫ßn ph·∫£i th√™m namespace
### 4.2.1. ·ª®ng d·ª•ng
- Mu·ªën l∆∞u tr·ªØ c√°c ·ª©ng d·ª•ng c√≥ t·ªëc ƒë·ªô ƒë·ªçc ghi nhanh s·ª≠ d·ª•ng lo·∫°i storage class ssh ch·∫≥ng h·∫°n, c√°c ·ª©ng d·ª•ng l∆∞u tr·ªØ l√¢u d√†i 0 c·∫ßn nhanh th√¨ sd hdd
- C√°c lo·∫°i ph·ªï bi·∫øn tr√™n On-pre: NFS, CephFS
### 4.2.2. NFS 
- VD tr√™n server-database, ta c√†i NFS sau ƒë√≥ c√≥ ch·ª©c nƒÉng chia s·∫Ω 1 th∆∞ m·ª•c ra b√™n ngo√†i v√† tr√™n k8s c√†i NFS client th√¨ c√≥ th·ªÉ truy c·∫≠p ƒë∆∞·ª£c c√°i th∆∞ m·ª•c NFS server chia s·∫ª v√¨ v·∫≠y m√† ta c√≥ th·ªÉ mount d·ªØ li·ªáu c·ªßa db server l√™n 1 server ri√™ng ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu v√† c≈©ng l∆∞u d∆∞·ªõi d·∫°ng t·∫≠p trung
### 4.2.3. C√∫ ph√°p khai b√°o
```
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-storage
provisioner: kubernetes.io/no-provisioner (t√πy v√†o m√¥i tr∆∞·ªùng kh√°c nhau s·∫Ω c√≥ gi√° tr·ªã kh√°c)
VolumeBindingMode: WaitForFirstComumser
parameters:
  type: pd-ssd
```
VolumeBindingMode: 
- Immediate: ti·∫øn h√†nh li√™n k·∫øt v√†o khi m√† PVC ƒë∆∞·ª£c t·∫°o 
- WaitForFirstComumser: n√≥ s·∫Ω ch·ªù c√≥ 1 consumer s·ª≠ d·ª•ng ƒë·∫ßu ti√™n th√¨ m·ªõi ƒë∆∞·ª£c √°p d·ª•ng ch·ªâ ƒë∆∞·ª£c t·∫°o khi c√≥ Pod s·ª≠ d·ª•ng
## 4.3. PV (Persistent Volume) v√† PVC (Persistent Volume Claim)
### 4.3.1. PV l√† g√¨? 
- L√† 1 ƒë·ªëi t∆∞·ª£ng cung c·∫•p kh·∫£ nƒÉng l∆∞u tr·ªØ b·ªÅn v·ªØng
- C√≥ th·ªÉ l∆∞u tr·ªØ c√°c ngu·ªìn kh√°c nhau nh∆∞ PVs, EVs... 
- V√≠ d·ª•: "Ti·ªám b√°nh: `L√† 1 ph·∫ßn c·ª• th·ªÉ trong kho, nh∆∞ c√°i t·ªß ch·ª©a b√°nh m√† ti·ªám s·∫µn s√†ng ƒë·ªÉ l∆∞u tr·ªØ, c√≥ t·ªß nh·ªè t·ªß l·ªõn t√πy theo k√≠ch th∆∞·ªõc`". C√≤n trong k8s: `L√† t√†i nguy√™n ƒë∆∞·ª£c khai b√°o 1 v√πng ch·ª©a. Nh∆∞ kh·ªüi t·∫°o 1 v√πng ch·ª©a v·ªõi 10GB b·ªô nh·ªõ => d√†nh ra 1 v√πng nh·ªõ ri√™ng v·ªõi 10GB b·ªô nh·ªõ `
### 4.3.2. PVC l√† g√¨? 
- L√† 1 y√™u c·∫ßu t·ª´ ng∆∞·ªùi d√πng ƒë·ªÉ s·ª≠ d·ª•ng 1 l∆∞·ª£ng l∆∞u tr·ªØ c·ª• th·ªÉ, cho ph√©p ng∆∞·ªùi d√πng y√™u c·∫ßu dung l∆∞·ª£ng l∆∞u tr·ªØ v√† ch·∫ø ƒë·ªô truy c·∫≠p 
- V√≠ d·ª•: "Ti·ªám b√°nh: `PVC nh∆∞ c√°ch m√† nh√¢n s·ª± y√™u c·∫ßu T√¥i mu·ªën 1 c√°i t·ªß ƒë·ªÉ t√¥i ƒë·ªÉ 10 chi·∫øc b√°nh c≈©ng nh∆∞ nguy√™n li·ªáu c·ªßa chi·∫øc b√°nh ƒë√≥ v√† c√≥ th·ªÉ ƒë·ªÉ v·ª´a c√°i t·ªß ƒë√≥ `. C√≤n trong k8s: `PVC nh∆∞ 1 y√™u c·∫ßu sd t√†i nguy√™n nh∆∞ l√† PV m√† ta ƒë√£ t·∫°o, nh∆∞ t·∫°o 1 PV v·ªõi 10GB v√† 1 PVC l√† 5GB th√¨ n√≥ s·∫Ω t√¨m c√°i PV n√†o ph√π h·ª£p y√™u c·∫ßu ƒë√≥ v√† sd`"
### 4.3.3. Nh·ªØng ph·∫ßn ƒë·∫∑c bi·ªát ph·∫£i bi·∫øt khi s·ª≠ d·ª•ng PV v√† PVC 
- Type of Persistent Volumes: C√≥ r·∫•t l√† nhi·ªÅu lo·∫°i v√† m·ªói lo·∫°i s·∫Ω c√≥ m·ªôt y√™u c·∫ßu kh√°c nhau 

    ![alt text](Images/Type-of-PV.png)
- hostPath: l∆∞u tr·ªØ tr·ª±c ti·∫øp tr√™n server c√†i ƒë·∫∑t k8s lu√¥n nh∆∞ng kh√≥ ƒë·ªìng b·ªô v√¨ n·∫øu pod chuy·ªÉn sang server kh√°c t√¨ s·∫Ω kh√¥ng c√≥ d·ªØ li·ªáu -> SD ƒë·ªÉ test
- Access Modes: 
    - ReadWriteOnce: QH 1:1 ƒëang mount 1 pod v√†o 1 mount point v√† n·∫øu scale l√™n 2 pod th√¨ ch·∫Øc ch·∫Øn s·∫Ω 0 ƒë∆∞·ª£c 
    - ReadOnlyMany: Ch·ªâ c√≥ quy·ªÅn ƒë·ªçc
    - ReadWriteMany: QH 1:N (1mount point c√≥ t·ª´ b√™n ngo√†i c√≥ th·ªÉ ƒë∆∞·ª£c ƒë·ªçc t·ª´ nhi·ªÅu pod trong c·ª•m)
    - ReadWriteOncePod: Ch·ªâ c√≥ 1 pod duy nh·∫•t ƒë∆∞·ª£c ƒë·ªçc-ghi n√≥. ƒê·∫£m b·∫£o r·∫±ng tr√™n to√†n c·ª•m ch·ªâ c√≥ pod ƒë√≥ ƒë∆∞·ª£c ph√©p ƒë·ªçc PVC ho·∫∑c ghi.
- Reclaim Policy: Quy·∫øt ƒë·ªãnh PV khi PVC b·ªã x√≥a ƒëi -> quy·∫øt ƒë·ªãnh PV l√†m g√¨ v√† ch·ªâ c√≥ (nfs v√† hostPath th√¨ m·ªõi h·ªó tr·ª£ t√≠nh nƒÉng n√†y)
  - Retain(Gi·ªØ l·∫°i): Khi PVC kh√¥ng sd PV n√†y n·ªØa th√¨ n√≥ s·∫Ω gi·ªØ l·∫°i d·ªØ li·ªáu
  - Recycle: X√≥a ƒë∆°n gi·∫£m (rm -rf /thevolume/*)
  - Delete: Khi kh√¥ng c√≥ y√™u c·∫ßu n√†o cho PV th√¨ n√≥ s·∫Ω x√≥a h·∫øt d·ªØ li·ªáu
- Phase: C√°c giai ƒëo·∫°n
### 4.3.4. C√∫ ph√°p, c√¢u l·ªánh
#### 4.3.4.1. PVC Example
    ```
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
    name: app-storage
    spec:
    accessModes: ["ReadWriteOnce"]
    resources:
        requests:
        storage: 1Gi
    ```
- Pod using the PVC
    ```
    volumes:
    - name: app-data
        persistentVolumeClaim:
        claimName: app-storage

    containers:
    - name: web
        volumeMounts:
        - name: app-data
            mountPath: /data
    ```
### 4.3.5. S·ª≠ d·ª•ng v√†o d·ª± √°n 
- T·∫°o 1 server ho·∫∑c s·ª≠ d·ª•ng `database-server` t·∫°o 1 disk ri√™ng sau ƒë√≥ s·ª≠ d·ª•ng n√≥ ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu 
- C√†i ƒë·∫∑t NFS server `sudo apt install nfs-server`
- Sau ƒë√≥ mu·ªën mount d·ªØ li·ªáu v√†o th∆∞ m·ª•c /data
    ```
    sudo -i
    mkdir /data
    chown -R nobody:nogroup  /data
    chmod -R 777 /data
    ```
    `sudo vi /etc/exports` th√™m 1 d√≤ng `/data *(rw,syn,no_subtree_check)`: Mount th∆∞ m·ª•c /data v·ªõi * t·∫•t c·∫£ c√°c ƒë·ªãa ch·ªâ truy c·∫≠p mode rqq syn
    
    ```
    exportfs -rav
    sudo systemctl restart nfs-kernal-server
    ```
- V√† tr√™n k8s mu·ªën k·∫øt n·ªëi ƒë∆∞·ª£c th√¨ `k8s-master-1` ph·∫£i c√†i nfs-common th√¨ m·ªõi k·∫øt n·ªëi ƒë∆∞·ª£c ***C√†i tr√™n t·∫•t c·∫£ c√°c server**
    ```
    sudo -i
    apt install nfs-common -y
    ```
- Sau ƒë√≥ quay l·∫°i rancer v√† tri·ªÉn khai PV v√† PVC
    - PV
    ```
    apiVersion: v1
    kind: PersistenVolume
    metadata:
        name: nfs-pv
    spec:
        capacity:
            storage: 10Gi
        accessModes:
            - ReadWriteMany
        nfs:
            path: /data
            server: 192.168.1.115
        persistenVolumeReclaimPolicy: Retain
        storageClassName: nfs-storage
    ```
    - PVC
    ```
    apiVersion: v1
    kind: PersistenVolumeClaim
    metadata:
        name: nfs-pvc
        namespace: ecommerce
    spec:
        accessModes:
            - ReadWriteMany
        resources:
            requests:
                storage: 5Gi
        storageClassName: nfs-storage
    ```
    - Sau ƒë√≥ v√†o ph·∫ßn Recent Events ƒë·ªÉ ki·ªÉm tra tr·∫°ng th√°i -> message `waiting for first common,...` c·∫ßn ph·∫£i c√≥ 1 pod s·ª≠ d·ª•ng
    - T·∫°o 1 pod ƒë·ªÉ k·∫øt n·ªëi d·ªØ li·ªáu: Pod nginx mount d·ªØ li·ªáu t·ª´ Pod v√†o th∆∞ m·ª•c /data c·ªßa NFS server
    ```
    apiVersion: v1
    kind: Pod
    metadata:
      name: nfs-nginx
      namespace: ecommerce
    spec:
      containers:
        - image: nginx
          name: nginx
          volumeMounts:
            - mountPath: /usr/share/nginx/html
              name: nfs-storage
      volumes:
        - name: nfs-storage
          persistentVolumeClaim:
            claimName: nfs-pvc
    ```
- **T√≥m t·∫Øt l·∫°i quy tr√¨nh: ƒê·∫ßu ti√™n c·∫ßn t·∫°o 1 storageClass ƒë·ªÉ khai b√°o lo·∫°i g√¨, ti·∫øp ƒë·∫øn t·∫°o 1 server NFS ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu -> Sau ƒë√≥ t·∫°o 1 PV ƒë·ªÉ khai b√°o 1 v√πng ch·ª©a tr·ªëng v√† PVC ƒë·ªÉ y√™u c·∫ßn n∆°i l∆∞u tr·ªØ d·ªØ li·ªáu d·ª±a tr√™n c√°c PV c√≥ s·∫µn v√† cu·ªëi c√πng l√† mount th∆∞ m·ª•c b√™n trong pod tr√™n k8s v√†o NFS-server**
## 4.4. Tri·ªÉn khai mariadb 
### 4.4.1. StatefulSet
- Gi√∫p qu·∫£n l√Ω tr·∫°ng th√°i, t√≠nh ·ªïn ƒë·ªãnh cao nh∆∞ database
- T√†i nguy√™n ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn khi sd c√πng v·ªõi PV, ƒë∆∞·ª£c d√πng ƒë·ªÉ t·∫°o database tr√™n k8s
- L√† 1 API resource ƒë∆∞·ª£c sd ƒë·ªÉ qu·∫£n l√Ω vi·ªác tri·ªÉn khai v√† m·ªü r·ªông c√°c ·ª©ng d·ª•ng c√≥ tr·∫°ng th√°i v√† kh√°c v·ªõi deployment, ph√π h·ª£p cho vi·ªác ƒë·∫£m b·∫£o t√≠nh to√†n v·∫πn c·ªßa d·ªØ li·ªáu v√† duy tr√¨nh t√≠nh ·ªïn ƒë·ªãnh c·ªßa c√°c pod 
- C≈©ng kh·ªüi t·∫°o c√°c pod nh∆∞ng c√°c pod s·∫Ω kh·ªüi t·∫°o l·∫ßn l∆∞·ª£t c√≥ t√™n v√† th·ª© t·ª± 
### 4.4.2. Tri·ªÉn khai 
- Tri·ªÉn khai 1 mariadb
    ```
    apiVersion: v1
    kind: StatefulSet
    metadata:
        name: mariadb
        namespace: ecommerce
    spec:
        serviceName: mariadb-service
        replicas: 1
        selector: 
            matchLabels:
                app: mariadb
        template:
            metadata:
                labels:
                    app: mariadb
            spec:
                securityContext:
                    fsGroup: 65534
                containers:
                    - name: mariadb
                    image: mariadb-latest
                    env:
                        - name: MYSQL_ROOT_PASSWORD
                        value: "devopseduvn"
                    ports:
                        - contianerPort: 3306
                        name: mysql
                    volumeMounts:
                        - name: mariadb-storage
                        mountPath: /var/lib/mysql
                volumes:
                    - name: mariadb-storage
                    persistenVolumeClaim:
                        claimName: nfs-pvc
    ```
    > securityContext:
    >                fsGroup: 65534
    `ƒê·∫°i di·ªán cho UID l√† nobody`
- Sau ƒë√≥ s·ª≠a l·∫°i file `vi /etc/exports` 
    - Th√™m t√πy ch·ªçn `/data *(rw,sync,no_subtree_check,no_root_squash)` v√† √°p d·ª•ng `sudo exportfs -rav`
    ```
    sudo exportfs -rav
    sudo systemctl restart nfs-server
    ```
- L∆∞u tr·ªØ d·ªØ li·ªáu trong /data
- T·∫°o NodePort ƒë·ªÉ k·∫øt n·ªëi t·ª´ b√™n ngo√†i v√†o ki·ªÉm tra k·∫øt n·ªëi 

    ```
    apiVersion: v1
    kind: Service
    metadata:
        name: mariadb-service
        namespace: ecommerce
    spec:
        selector:
            app: mariadb
        type: NodePort
        ports:
            - port: 3306
            targetPort: 3306
            nodePort: 31306
    ```
- K·∫øt n·ªëi `mysql -h 192.168.1.111 -P 31306 -u root -p`
- K·∫øt n·ªëi tr·ª±c ti·∫øp v·ªõi nhau
##  4.5. Tri·ªÉn khai Redis (Helm)
- L√† c√¥ng c·ª• h·ªá h·ªëng qu·∫£n tr·ªã CSDL no SQL l∆∞u tr·ªØ d∆∞·ªõi d·∫°ng **key: value** cho ph√©p truy c·∫≠p c·ª±c nhanh v√† c√°c d·ª± √°n theo m√¥ h√¨nh microservices 
- B√†i to√°n: Tri·ªÉn khai 1 redis ƒë·∫£m b√°o t√≠nh HA tr√™n 1 namespace ri√™ng s·∫Ω th·ª≠ k·∫øt n·ªëi t·ª´ d·ª± √°n ecommerce ƒë·∫øn c√°i redis ƒë√≥ ·ªü b√™n trong m√¥i tr∆∞·ªùng c·ª•m k8s v√† kh√¥ng k·∫øt n·ªëi ra b√™n ngo√†i
- Truy c·∫≠p v√†o `k8s-master-1`: **kubectl create ns architecture**
- Quay tr·ªü l·∫°i `database-server`
    ```
    ls /data
    mkdir /data/redis
    chown -R nobody:nogroup /data/
    chmod -R 777 /data/
    ```
- T·∫°o PV v√† PVC
    ```
    apiVersion: v1
    kind: PersistenVolume
    metadata:
        name: redis-pv
    spec:
        capacity:
            storage: 10Gi
        accessModes:
            - ReadWriteMany
        nfs:
            path: /data/redis/
            server: 192.168.1.115
        persistenVolumeReclaimPolicy: Retain
        storageClassName: nfs-storage
    ---
    apiVersion: v1
    kind: PersistenVolumeClaim
    metadata:
        name: redis-pvc
        namespace: architecture
    spec:
        accessModes:
            - ReadWriteMany
        resources:
            requests:
                storage: 10Gi
        storageClassName: nfs-storage
    ```
- Quay l·∫°i `k8s-master-1` v√† b·∫Øt ƒë·∫ßu c√†i ƒë·∫∑t Redis b·∫±ng helm chart 

    ```
    mkdir redis
    cd redis
    ```
# 5. Gi√°m s√°t v√† qu·∫£n tr·ªã Kubernetes 
- Tri·ªÉn kh√°m s√°t node, pod, namespace, ... c√°c t√†i nguy√™n tr√™n c·ª•m k8s, c·∫£nh b√°o downtime c·ªßa website
- Gi√°m s√°t ngo√†i c·ª•m 
## 5.1. Daemonsets
- T√†i nguy√™n quy chu·∫©n cho monitoring v√† loging
- ƒê∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng m·ªói pod s·∫Ω ch·∫°y tr√™n t·∫•t c·∫£ c√°c node trong cluster khi s·ª≠ d·ª•ng daemonsets th√¨ k8s s·∫Ω t·ª± ƒë·ªông t·∫°o b·∫£n sao c·ªßa pod ƒë√≥ tr√™n m·ªói node v√† khi c√≥ m·ªôt node n√†o ƒë√≥ ƒë∆∞·ª£c th√™m trong k8s th√¨ daemonsets s·∫Ω t·ª± ƒë·ªông t·∫°o th√™m pod v·ªõi t√†i nguy√™n daemonsets tr√™n node ƒë√≥ 
- Ch√≠nh v√¨ daemonsets ch·∫°y pod tr√™n t·∫•t c·∫£ c√°c node n√™n s·∫Ω c√≥ th·ªÉ thu th·∫≠p ƒë∆∞·ª£c c√°c tr·∫°ng th√°i c·ªßa t√†i nguy√™n.
- T√†i nguy√™n c√≥ s·∫µn calico tr√™n k8s cung c·∫•p t√≠nh nƒÉng network policy cho k8s cho ph√©p thi·∫øt l·∫≠p c√°c quy t·∫Øt b·∫£o m·∫≠t cho m·∫°ng ·ªü trong c·ª•m k8s ƒë·ªÉ h·∫°n ch·∫ø l∆∞u l∆∞·ª£ng truy c·∫≠p gi·ªØa c√°c pod, c√°c namespace 
- L·∫•y c√°c daemonset: `kubectl get ds -A`
- Taints and tolerations: M·∫∑c ƒë·ªãnh s·∫Ω tri·ªÉn khai tr√™n t·∫•t c·∫£ c√°c worker nh∆∞ng m√† c√≥ th·ªÉ ngƒÉn ch·∫∑n daemonsets kh·ªüi t·∫°o pod tr√™n 1 node c·ª• th·ªÉ n√†o ƒë√≥ ƒë·ªÉ kh√¥ng cho ph√©p gi√°m s√°t c√°i node ƒë√≥ 
## 5.2. Gi√°m s√°t s·ª≠ d·ª•ng prometheus 
- APM (application performance management): C√¥ng c·ª• gi√°m s√°t d·ª± √°n ƒëang ch·∫°y c√≥ hi·ªáu su·∫•t nh∆∞ th·∫ø n√†o, c√°c ƒë·ªô tr·ªÖ cao hay th·∫•p, ph·∫ßn trƒÉm t·ªâ l·ªá l·ªói
### 5.2.1. M√¥ h√¨nh PNG (prometheus node exporter grafana)
![alt text](Images/diagram-monitoring.png)
- Gi√°m s√°t th√¥ng qua c√°c c√¥ng c·ª• **Node exporter, SNMP exporter,..** sau ƒë√≥ prometheus s·∫Ω ti·∫øn h√†nh thu th·∫≠p c√°c d·ªØ li·ªáu v·ªÅ v√† ƒë∆∞·ª£c g·ªçi m√† metric -> Grafana
### 5.2.2. C√†i ƒë·∫∑t (helm)
- `Prometheus chart`
1. L∆∞u d·ªØ li·ªáu ra b√™n ngo√†i ƒë·ªÉ ƒë·∫£m b·∫£o r·∫±ng n·∫øu h·ªá th·ªëng monitoring c√≥ b·ªã reset c≈©ng kh√¥ng m·∫•t d·ªØ li·ªáu 
2. Truy c·∫≠p v√†o `database-server` 

    ```
    mkdir /data/monitoring
    chown -R nobody:nogroup /data/
    chmod -R 777 /data/
    ```
3. Quay l·∫°i rancher v√† t·∫°o m·ªôt project v√† namespace m·ªõi (monitoring) v√† ti·∫øn h√†nh tri·ªÉn khai png stack tr√™n ƒë√¢y
4. T·∫°o 1 pv m·ªõi 
    ``` 
    apiVersion: v1
    kind: PersistentVolume
    metadata: 
        name: monitoring-pv
    spec:
        capacity:
            storage: 10Gi
        accessMode: 
            - ReadWriteOnce
    nfs:
        path: /data/monitoring
        server: 192.168.1.115
    persistentVolumeReClaimPolicy: Retain
    storageClassName: nfs-storage
    ```
5. Sau ƒë√≥ v√†o git helm chart c·ªßa prometheus ƒë·ªÉ tri·ªÉn khai l√™n k8s-master-1
    ```
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    helm repo update
    helm upgrade --install anphucvn prometheus-community/kube-prometheus-stack 
      --namespace monitoring 
      --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.accessModes[0]=ReadWriteOnce 
      --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=10Gi 
      --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName=nfs-storage
    ```
6. Sau khi c·∫•u h√¨nh th√†nh c√¥ng quay l·∫°i ki·ªÉm tra c√°c tr·∫°ng th√°i tr√™n monitoring 
![alt text](Images/status-workloads.png)
    
    ```
    helm pull prometheus-community/kube-prometheus-stack
    tar -xvf kube-prometheus-stack...
    ```
    vi values.yaml
    ```
    /ingress
    enabled: true
    ```
7. T·∫°o nhanh ingress b·∫±ng c√°ch Services-> Ingress 
    
    ```
    host: grafana.anphuc.vn
    Prefix: /
    anphucvn-grafana
    port: 80
    IngressClass: nginx
    ```
    Add host tr√™n win: `192.168.1.110 grafana.anphuc.vn`
    Sau ƒë√≥ truy c·∫≠p v·ªõi username v√† mk ·ªü Store-> Secret `anphuc-grafana`
8. L√†m t∆∞∆°ng t·ª± v·ªõi prometheus port 8080
## 5.3. DashBoard Grafana
- Dashboards quan tr·ªçng
    - Khi l√†m vi·ªác tr√™n k8s th·ª±c thi nh·ªØng c√¢u l·ªánh, nh·ªØng thao t√°c m√† n√≥ b·ªã ch·∫≠m th√¨ v√†o **API server** ki·ªÉm tra c√°c rate, c√°c lo·∫°i SLI-request , d·ªô tr·ªÖ
    - D·ª± √°n b·ªã ch·∫≠m v√≠ d·ª• `ecommerce` x√°c nh·∫≠n xem d·ª± √°n ƒë√≥ c√≥ b·ªã chaamh hay kh√¥ng ta th∆∞·ªùng xem v√†o 2 ph·∫ßn t√†i nguy√™n `Namespace(workloads)`, `Pod`, `Cluster`(CPU, memory) v√† m·∫°ng (bandwitch) `Namespace(workloads)`
- Khi b·ªã request cao th√¨ n√™n v√†o xem dashboard gi√°m s√°t
## 5.4. Uptime kuma (helm)
- Theo d√µi ƒë∆∞·ª£c kh·∫£ nƒÉng uptime c·ªßa 1 website 
- Search: `http request status` ƒë·ªÉ xem c√°c tr·∫°ng th√°i c·ªßa website
- blackbox uptume trong prometheus
- Uptime-kuma helm chart
### 5.4.1. C·∫•u h√¨nh 
- T·∫°o PV v√† PVC ƒë·ªÉ l∆∞u tr·ªØ l·∫°i nh·ªØng tr·∫°ng th√°i m√† ta gi√°m s√°t

    - Tr√™n `k8s-master-1`
    ```
    mkdir uptime
    cd uptime 
    ```
    vi values.yaml
    ``` 
    volume:
        enable: true
        accessMode: ReadWriteOnce
        existingClaim: "uptime-kuma-pvc"
    ---
    helm install anphucvn-uptime uptime-kuma/uptime-kuma -n monitoring -f values.yaml
    ```
- Sau ƒë√≥ t·∫°o ingress ƒë·ªÉ c√≥ th·ªÉ truy c·∫≠p ƒë∆∞·ª£c v√†o uptime
    ```
    Name: uptime-ingress
    requestHost: uptime.anphuc.vn
    Prefix: /
    Target: anphucvn-uptime-uptime-kuma
    Port: 3001
    IngressClass: Nginx
    ```
- Add host tr√™n win: **192.168.1.110 uptime.anphuc.vn**
### 5.4.2. Truy c·∫≠p v√† t√πy ch·ªânh giao di·ªán
- Add new Monitor
    ```
    Friendly Name: ecommerce.anphuc.vn
    url: ....
    Retries: 3 (Ki·ªÉm tra l·ªói qu√° s·ªë l·∫ßn th√¨ ti·∫øn h√†nh c·∫£nh b√°o )
    Accepted Status Codes: 200-299
    Setup Notification: ....
    ```
- T√≠ch h·ª£p c√¥ng c·ª• l√™n grafana ƒë·ªÉ ti·∫øn h√†nh gi√°m s√°t t·∫≠p trung 
  - Ph·∫£i add host v√†o deployment `anphucvn-uptime-uptime-kuma` -> Networking -> Host Alias: ....
  - T·∫°o API Keys v√† d√πng c√°i key ƒë·ªÉ x√°c th·ª±c, c√≥ th·ªÉ **/metrics** ƒë·ªÉ ki·ªÉm tra c√°c tr·∫°ng th√°i c√≥ th·ªÉ thu th·∫≠p ƒë∆∞·ª£c l√™n prometheus sau ƒë√≥ ƒë∆∞a v√†o giao di·ªán grafana
- C√≥ nhi·ªÅu ph·∫ßn n·ª´a: 
  - H·∫° t·∫ßn container, loging c·ªßa d·ª± √°n
  - L√†m sao ƒë·ªÉ bi·∫øt performent c·ªßa d·ª± √°n ƒëang ·ªü m·ª©c n√†o
  - L∆∞·ª£ng trafic v√†o ra 
## 5.5. Backup
### 5.5.1. Backup nh·ªØng g√¨?
- **PV v√† PVC**: S·ª≠ d·ª•ng **NF Server** l∆∞u tr·ªØ d·ªØ li·ªáu kh√°c ngo√†i c·ª•m, ƒë·∫£m b·∫£o d·ªØ li·ªáu, v√† c√≥ th·ªÉ ch·∫°y **crontab**(Backup t·ª± ƒë·ªông)
- **S·ª≠ d·ª•ng 1 cluster v√† 2 replica** t·∫°o b·∫£n backup ·ªü server b√™n ngo√†i th∆∞·ªùng 5 b·∫£n
- Backup c√°c file yaml ra 1 n∆°i t·∫≠p trung nh∆∞ git-ops, infastructor upcode gi√∫p ƒë·∫£m b·∫£o khi kh·ªüi t·∫°o l·∫°i c≈©ng nh∆∞ ƒë·ªìng b·ªô d·ª± √°n h·∫° t·∫ßng s·∫Ω ƒë·ªìng nh·∫•t v√† b·∫£o ƒë·∫£m 
- C√°c **Secrets** v√† **config-map**: nh∆∞ kms, pause 
- C√°c manifest tri·ªÉn khai tr√™n k8s
- ECTD: l∆∞u tr·ªØ to√†n b·ªô tr·∫°ng th√°i c·ªßa c·ª•m
- C√°c Cluster l·ªõn v√† ph·ª©c t·∫°p: backup c·∫£ cluster metadata hay infastructer config ..., c√°c c∆° s·ªü h·∫° t·∫ßng, th√¥ng tin v·ªÅ network, firewall rules, ... Ensible, Cloud (Teraform)
- Monitoring & logging: c√°c t√†i nguy√™n dashboard, c·∫•u h√¨nh metric,...
### 5.5.2. Backup and Restore 
- Backup k8s v√† c√¥ng c·ª•: `K8S backup`
- Velero: C√¥ng c·ª• backup ECTD: c·∫£ tr·∫°ng th√°i c·ªßa ectd, PV kh√¥i ph·ª•c v√† sao l∆∞u theo l·ªãch tr√¨nh
- ectdclt: C√¥ng c·ª• backuo ƒë∆∞·ª£c ectd ch·ªß y·∫øu sao l∆∞u v√† kh√¥i ph·ª•c tr·∫°ng th√°i c·ªßa ectl kh√¥ng h·ªô tr·ª£ PV v√† PVC
#### 5.5.2.1. Velero
- Velero release: [GitHub](https://github.com/vmware-tanzu/velero/releases)

    ![alt text](image.png)
- Tr√™n `k8s-master-1`
    ```
    wget https://github.com/vmware-tanzu/velero/releases/download/v1.16.1/velero-v1.16.1-linux-amd64.tar.gz
    tar -xvf ...
    sudo mv velero-version... /usr/local/bin
    velero version
    ```
- L∆∞u b·∫£n backup ra ƒë√¢u: `MinIO` kho l∆∞u tr·ªØ v√† t·∫°o c√°c packet l∆∞u tr·ªØ d·ªØ li·ªáu l√™n ƒë√≥ c√≥ th·ªÉ th·∫•y doanh nghi·ªáp c√≥ bank, thu·∫≠t to√°n, t·ª± d·ª±ng ·ªü on-premit
- S·ª≠ d·ª•ng `database-server` ƒë·ªÉ l∆∞u d·ªØ li·ªáu ho·∫∑c mount ra ·ªü 1 v·ª• tr√≠ kh√°c b√™n ngo√†i
#### 5.5.2.2. C√†i ƒë·∫∑t
- C√†i ƒë·∫∑t s·ª≠ d·ª•ng docker: tr√™n `database-server`
    ```
    mkdir /minio
    cd minio
    ```
    vi docker-compose.yml
    ```
    version: '3'
    services:
      minio:
        image: minio/minio
        container_name: minio
        ports:
          - "9000:9000"
          - "9001:9001"
        volumes:
          - ./storage:/data
        environment:
          MINIO_ROOT_USER: anphuc
          MINIO_ROOT_PASSWORD: Anphuc@1231
        command: server --console-address ":9001" /data

    ```
- Ch·∫°y l·ªánh `docker-compose up -d` s·ª≠ d·ª•ng port 9000 v√† 9001, `docker ps`
- Truy c·∫≠p `192.168.1.115:9001`
- Create buket `k8s-anphucvn-cluster-backup`
- ƒê·ªÉ l∆∞u tr·ªØ th√¨ c·∫ßn qua API v√† x√°c th·ª±c qua `secret key v√† access key`
- Quay l·∫°i `k8s-master-1` 

    ![alt text](image-1.png)

    ```
    export MINIO_URL="192.168.1.115:9000"
    export MINIO_ACCESS_KEY_ID="..."
    export MINIO_ACCESS_KEY_ID="..."
    export MINIO_BUCKET="k8s-anphucvn-cluster-backup"
    ```
- Ch·∫°y l·ªánh ƒë·ªÉ c√†i ƒë·∫∑t Velero v·ªõi MinIO l√†m backend l∆∞u tr·ªØ c√°c b·∫£n sao l∆∞u c·ªßa Kubernetes (th·ª±c hi·ªán tr√™n server `k8s-master-1` ho·∫∑c kubectl shell Rancher)
    ```
    velero install 
    --provider aws 
    --bucket $MINIO_BUCKET 
    --secret-file <(echo -e "[default]naws_access_key_id=$MINIO_ACCESS_KEY_IDnaws_secret_access_key=$MINIO_SECRET_KEY_ID") 
    --use-node-agent 
    --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=$MINIO_URL 
    --plugins velero/velero-plugin-for-aws:v1.5.0 
    --namespace velero
    ```
- Ki·ªÉm tra tr√™n rancher-server s·∫Ω th·∫•y ƒë∆∞·ª£c m·ªôt namespace `velero` m√† ta t·∫°o ra 
    - V√†o namespace ki·ªÉm tra th√¨ th·∫•y c√°c t√†i nguy√™n, workloads ƒë√£ ƒë∆∞·ª£c t·∫°o ra 
    - V√†o Storage -> Secrets: c√≥ 2 c√°i secret nh∆∞ c√°c key m√¨nh t·∫°o ra 
    - C√¢u l·ªánh xem log: 
#### 5.5.2.3. Ti·∫øn h√†nh backup t·ª´ng ph·∫ßn 
1. Backup d·ª± √°n ecommece 
- Tr√™n `k8s-master-1`: Backup to√†n b·ªô d·ª± √°n ecommerce lu√¥n c√≤n ta c√≥ th·ªÉ t·ª± t√¨m hi·ªÉu th√™m v√≠ d·ª• nh∆∞ backup ch√≠nh x√°c c√°i deployment n√†o hay c√°i PV n√†o ƒë√≥
    ```
    velero backup create ecommerce-v1 --include-namespaces=ecommerce
    velero backup get (Xem backup)
    ```
- Quay l·∫°i web Velero th√¨ th·∫•y l∆∞·ª£ng t√†i nguy√™n ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng

    ![alt text](image-2.png)
- Th·ª≠ x√≥a ƒëi d·ª± √°n `ecommerce backend` delete deployment sau ƒë√≥ d·ª±a theo backup ta ti·∫øn h√†nh restore l·∫°i b·∫±ng l·ªánh: 
    ```
    velero restore create ecommerce-v1 --from-backup ecommerce-v1 --include-namespaces ecommerce
    velero get restore
    ```
- Quay l·∫°i web rancher th√¨ th·∫•y d·ª± √°n ƒë√£ ƒë∆∞·ª£c backup l·∫°i v√† t∆∞∆°ng ·ª©ng th√¨ tr√™n web velero th√¨ s·∫Ω c√≥ m·ªôt b·∫£n restore t∆∞∆°ng ·ª©ng
- V√† n·∫øu mu·ªën x√≥a backup th√¨ ta d√πng l·ªánh
    ```
    velero backup detete ecommerce-v1
    ```
- Th·ª≠ backup to√†n c·ª•m
    ```
    velero backup create all-cluster-v1 --include-namespaces '*'
    ```
- V√† khi t√¨m hi·ªÉu th√™m th√¨ ho√†n ho√†n c√≥ th·ªÉ ƒë·∫∑t l·ªãch ƒë·ªÉ n√≥ c√≥ th·ªÉ t·ª± ƒë·ªông backup v√† n√≥ c√≥ th·ªÉ backup h·∫±ng ng√†y 
    ```
    velero schedule create daily-cluster-backup --schedule="0 0 * * *" --include-namespaces '*'
    velero schedule get
    velero schedule delete daily-cluster-backup
    ```